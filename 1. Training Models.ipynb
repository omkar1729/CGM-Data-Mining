{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.preprocessing as pre\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from scipy.stats import linregress as lr\n",
    "from scipy.signal import find_peaks as find_peaks\n",
    "from scipy.fftpack import fft, ifft,rfft\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.optimize import curve_fit\n",
    "import pickle\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.svm import SVC, NuSVC, LinearSVC\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import VotingClassifier, RandomTreesEmbedding, AdaBoostClassifier, RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Feature Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Globals\n",
    "COLUMNS = np.array(['Slope_minmax', \n",
    "           'PeakVal1_error', 'PeakVal2_error', 'PeakHt1_error', 'PeakHt2_error', \n",
    "           'Min1_window', 'Min2_window', 'Max1_window', 'Max2_window', 'Var1_window', 'Var2_window', 'Mean1_window', 'Mean2_window', \n",
    "           'Sig_coef1','Sig_coef2','Sig_coef3','Sig_coef4',\n",
    "           'Max_fft', 'Min_fft', 'Mean_fft', 'Var_fft'\n",
    "          ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CalcFeatureSet1(cgmNorm_np, cgmSeries_np):\n",
    "    maxs = np.argmax(cgmNorm_np, axis=1)\n",
    "    mins = [np.argmin(cgmNorm_np[i, maxs[i]:])+maxs[i] for i in range(len(maxs))]\n",
    "\n",
    "    slopes = []\n",
    "    time_diffs = []\n",
    "    for i in range(len(maxs)):\n",
    "        slope = (cgmNorm_np[i][maxs[i]]-cgmNorm_np[i][mins[i]])/(cgmSeries_np[maxs[i]]-cgmSeries_np[mins[i]])\n",
    "        time_diffs.append(cgmSeries_np[maxs[i]]-cgmSeries_np[mins[i]])\n",
    "        slopes.append(slope)\n",
    "\n",
    "    slopes = np.nan_to_num(slopes)\n",
    "    time_diffs = np.nan_to_num(time_diffs)\n",
    "    reg_window_size = 4\n",
    "    reg_errors = []\n",
    "    peak_values = []\n",
    "    peak_heights = []\n",
    "    peak_time_diffs = []\n",
    "    peak_times = []\n",
    "    for j in range(len(cgmNorm_np)):\n",
    "        errors = np.array([])\n",
    "        for i in range(len(cgmNorm_np[j])-reg_window_size):\n",
    "            times = cgmSeries_np[i:i+reg_window_size-1]\n",
    "            if np.isnan(times).any():\n",
    "                errors = np.append(errors, -1)\n",
    "                continue\n",
    "            coeffs = np.polyfit(times, cgmNorm_np[j][i:i+reg_window_size-1], 1)\n",
    "            poly = np.poly1d(coeffs)\n",
    "            error = poly(cgmSeries_np[i+reg_window_size])-cgmNorm_np[j][i+reg_window_size];\n",
    "            errors = np.append(errors, error)\n",
    "        peaks, height_dict = find_peaks(errors, height = 0)\n",
    "        heights = height_dict['peak_heights']\n",
    "        sorted_args = heights.argsort()\n",
    "        peaks = peaks[sorted_args]\n",
    "        peaks = peaks[-2:]\n",
    "        heights = heights[sorted_args]\n",
    "        heights = heights[-2:]\n",
    "        values = cgmNorm_np[j][peaks+reg_window_size-1]\n",
    "        times1 = cgmSeries_np[peaks+reg_window_size]\n",
    "        times2 = cgmSeries_np[peaks+reg_window_size-1]\n",
    "        reg_errors.append(errors)\n",
    "        while(len(values) < 2):\n",
    "            values = np.append(values, 0)\n",
    "            heights = np.append(heights, 0)\n",
    "            times1 = np.append(times, 0)\n",
    "            times2 = np.append(times2, 0)\n",
    "        peak_values.append(values)\n",
    "        peak_heights.append(heights)\n",
    "        peak_time_diffs.append(times1)\n",
    "        peak_times.append(times2)\n",
    "    reg_errors = np.array(reg_errors)\n",
    "    matrix = []\n",
    "    for i in range(0, len(cgmNorm_np)):\n",
    "        matrix_row = np.array([])\n",
    "        matrix_row = np.append(matrix_row, slopes[i])\n",
    "#         matrix_row = np.append(matrix_row, time_diffs[i])\n",
    "        matrix_row = np.append(matrix_row, peak_values[i])\n",
    "        matrix_row = np.append(matrix_row, peak_heights[i])\n",
    "#         matrix_row = np.append(matrix_row, peak_times[i])\n",
    "        matrix.append(matrix_row)\n",
    "    matrix = np.array(matrix)\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CalcFeatureSet2(cgmNorm_np, cgmSeries_np):\n",
    "    window_mins = []\n",
    "    window_maxs = []\n",
    "    window_means = []\n",
    "    window_vars = []\n",
    "    for i in range(0, len(cgmNorm_np)):\n",
    "        window_input = DataFrame(cgmNorm_np[i][::-1])\n",
    "        width=5\n",
    "        shifted=window_input.shift(width - 1)\n",
    "        window=shifted.rolling(window=width)\n",
    "        dataframe=concat([window.var(), window.min(),  window.mean(), window.max() ], axis=1)\n",
    "        dataframe.columns = ['var', 'min', 'mean', 'max']\n",
    "        window_features = dataframe.nlargest(2,'var')\n",
    "        window_values = window_features.values\n",
    "        window_mins.append([window_values[0][1], window_values[1][1]])\n",
    "        window_maxs.append([window_values[0][3], window_values[1][3]])\n",
    "        window_vars.append([window_values[0][0], window_values[1][0]])\n",
    "        window_means.append([window_values[0][2], window_values[1][2]])\n",
    "    \n",
    "    matrix = []\n",
    "    for i in range(0, len(cgmNorm_np)):\n",
    "        matrix_row = np.array([])\n",
    "        matrix_row = np.append(matrix_row, window_mins[i])\n",
    "        matrix_row = np.append(matrix_row, window_maxs[i])\n",
    "        matrix_row = np.append(matrix_row, window_vars[i])\n",
    "        matrix_row = np.append(matrix_row, window_means[i])\n",
    "        matrix.append(matrix_row)\n",
    "    matrix = np.array(matrix)\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x, L ,x0, k, b):\n",
    "    y = L / (1 + np.exp(-k*(x-x0)))+b\n",
    "    return (y)\n",
    "\n",
    "def CalcFeatureSet3(cgmNorm_np, cgmSeries_np):\n",
    "    n_series = []\n",
    "    n_datenum = []\n",
    "    sig1 = []\n",
    "    sig2 = []\n",
    "    sig3 = []\n",
    "    sig4 = []\n",
    "    for i in range(0, len(cgmNorm_np)):\n",
    "        idx = np.isfinite(cgmSeries_np) & np.isfinite(cgmNorm_np[i])\n",
    "        n_series.append(cgmNorm_np[i][idx])  \n",
    "        n_datenum.append(cgmSeries_np[idx])\n",
    "    for i in range(0,len(cgmNorm_np)):\n",
    "        if(len(n_series[i]) !=0 ):\n",
    "            try:\n",
    "                p0 = [max(n_series[i]), np.median(n_datenum[i]),250,min(n_series[i])] \n",
    "                popt, pcov = curve_fit(sigmoid, n_datenum[i], n_series[i],p0,method='trf')\n",
    "            except: \n",
    "                popt=[0,0,0,0]\n",
    "\n",
    "            sig1.append(popt[0])\n",
    "            sig2.append(popt[1])\n",
    "            sig3.append(popt[2])\n",
    "            sig4.append(popt[3])\n",
    "    \n",
    "    matrix = []\n",
    "    for i in range(0, len(cgmNorm_np)):\n",
    "        matrix_row = np.array([])\n",
    "        matrix_row = np.append(matrix_row, sig1[i])\n",
    "        matrix_row = np.append(matrix_row, sig2[i])\n",
    "        matrix_row = np.append(matrix_row, sig3[i])\n",
    "        matrix_row = np.append(matrix_row, sig4[i])\n",
    "        matrix.append(matrix_row)\n",
    "    matrix = np.array(matrix)\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CalcFeatureSet4(cgmNorm_np, cgmSeries_np):\n",
    "    Feature_vector=[]\n",
    "    for i in range(0, len(cgmNorm_np)):\n",
    "    #FFT\n",
    "        fastfouriertransform=rfft(cgmNorm_np[i])\n",
    "        fft_max=np.nanmax(fastfouriertransform)\n",
    "        s=np.where(fastfouriertransform == fft_max)\n",
    "        fft_min=np.nanmin(fastfouriertransform)\n",
    "        s=np.where(fastfouriertransform == fft_min)\n",
    "        fft_mean=np.nanmean(fastfouriertransform)\n",
    "        fft_variance=np.nanvar(fastfouriertransform)\n",
    "        Feature_vector.append(np.array([fft_max,fft_min,fft_mean,fft_variance]))\n",
    "    matrix = np.array(Feature_vector)\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MergedFeatures(cgmNorm_np, cgmSeries_np):\n",
    "    feature_set_1 = CalcFeatureSet1(cgmNorm_np, cgmSeries_np)\n",
    "    feature_set_2 = CalcFeatureSet2(cgmNorm_np, cgmSeries_np)\n",
    "    feature_set_3 = CalcFeatureSet3(cgmNorm_np, cgmSeries_np)\n",
    "    feature_set_4 = CalcFeatureSet4(cgmNorm_np, cgmSeries_np)\n",
    "    features = np.concatenate((feature_set_1, feature_set_2), axis=1)\n",
    "    features = np.concatenate((features, feature_set_3), axis=1)\n",
    "    features = np.concatenate((features, feature_set_4), axis=1)\n",
    "    features = np.nan_to_num(features)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenerateDF(features, columns):\n",
    "    feature_df = pd.DataFrame(features, columns=columns)\n",
    "    return feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NormalizeDF(feature_df, columns, max_scale):\n",
    "    for i in columns:\n",
    "        feature_df[i] = feature_df[i]/max_scale[i]\n",
    "    return feature_df\n",
    "#     means = feature_df.mean(axis=0)\n",
    "#     large_means = np.argwhere(means>1).flatten()\n",
    "#     small_means = np.argwhere(means<-1).flatten()\n",
    "#     for i in large_means:\n",
    "#         base = int(np.log10(means[i]))+1\n",
    "#         if base > 1:\n",
    "#             feature_df[columns[i]] = np.nan_to_num(np.log10(feature_df[columns[i]].replace(0, np.nan)))/base\n",
    "#     for i in small_means:\n",
    "#         base = int(np.log10(np.abs(means[i])))+1\n",
    "#         if base > 1:\n",
    "#             feature_df[columns[i]] = np.sign(feature_df[columns[i]])*np.nan_to_num(np.log10(np.abs(feature_df[columns[i]].replace(0, np.nan))))/base\n",
    "# #     print(large_means)\n",
    "#     return feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_no = [1, 2, 3, 4, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anikl9705/miniconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n",
      "/home/anikl9705/miniconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Slope_minmax</th>\n",
       "      <th>PeakVal1_error</th>\n",
       "      <th>PeakVal2_error</th>\n",
       "      <th>PeakHt1_error</th>\n",
       "      <th>PeakHt2_error</th>\n",
       "      <th>Min1_window</th>\n",
       "      <th>Min2_window</th>\n",
       "      <th>Max1_window</th>\n",
       "      <th>Max2_window</th>\n",
       "      <th>Var1_window</th>\n",
       "      <th>...</th>\n",
       "      <th>Mean1_window</th>\n",
       "      <th>Mean2_window</th>\n",
       "      <th>Sig_coef1</th>\n",
       "      <th>Sig_coef2</th>\n",
       "      <th>Sig_coef3</th>\n",
       "      <th>Sig_coef4</th>\n",
       "      <th>Max_fft</th>\n",
       "      <th>Min_fft</th>\n",
       "      <th>Mean_fft</th>\n",
       "      <th>Var_fft</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.223958</td>\n",
       "      <td>0.786632</td>\n",
       "      <td>0.6925</td>\n",
       "      <td>0.379195</td>\n",
       "      <td>0.418994</td>\n",
       "      <td>0.672222</td>\n",
       "      <td>0.663889</td>\n",
       "      <td>0.7300</td>\n",
       "      <td>0.726817</td>\n",
       "      <td>0.151981</td>\n",
       "      <td>...</td>\n",
       "      <td>0.702505</td>\n",
       "      <td>0.684127</td>\n",
       "      <td>-0.000179</td>\n",
       "      <td>0.157098</td>\n",
       "      <td>0.005127</td>\n",
       "      <td>0.001196</td>\n",
       "      <td>0.704449</td>\n",
       "      <td>-0.305146</td>\n",
       "      <td>0.634014</td>\n",
       "      <td>0.501904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.370180</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.197987</td>\n",
       "      <td>0.242086</td>\n",
       "      <td>0.419444</td>\n",
       "      <td>0.391667</td>\n",
       "      <td>0.4900</td>\n",
       "      <td>0.466165</td>\n",
       "      <td>0.091495</td>\n",
       "      <td>...</td>\n",
       "      <td>0.451461</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>-0.000178</td>\n",
       "      <td>0.105077</td>\n",
       "      <td>0.499994</td>\n",
       "      <td>0.000705</td>\n",
       "      <td>0.377450</td>\n",
       "      <td>-0.368154</td>\n",
       "      <td>0.351433</td>\n",
       "      <td>0.148848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.193182</td>\n",
       "      <td>0.519280</td>\n",
       "      <td>0.4700</td>\n",
       "      <td>0.308725</td>\n",
       "      <td>0.275605</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.230556</td>\n",
       "      <td>0.3975</td>\n",
       "      <td>0.358396</td>\n",
       "      <td>0.190450</td>\n",
       "      <td>...</td>\n",
       "      <td>0.328288</td>\n",
       "      <td>0.292593</td>\n",
       "      <td>0.000544</td>\n",
       "      <td>0.101382</td>\n",
       "      <td>0.003870</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>0.376598</td>\n",
       "      <td>-0.543992</td>\n",
       "      <td>0.284399</td>\n",
       "      <td>0.155170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.245536</td>\n",
       "      <td>0.383033</td>\n",
       "      <td>0.5350</td>\n",
       "      <td>0.305369</td>\n",
       "      <td>0.175047</td>\n",
       "      <td>0.341667</td>\n",
       "      <td>0.327778</td>\n",
       "      <td>0.4225</td>\n",
       "      <td>0.403509</td>\n",
       "      <td>0.098461</td>\n",
       "      <td>...</td>\n",
       "      <td>0.382568</td>\n",
       "      <td>0.360847</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>0.147579</td>\n",
       "      <td>0.124742</td>\n",
       "      <td>0.000625</td>\n",
       "      <td>0.433015</td>\n",
       "      <td>-0.226763</td>\n",
       "      <td>0.418339</td>\n",
       "      <td>0.191966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.100216</td>\n",
       "      <td>0.336761</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.171141</td>\n",
       "      <td>0.100559</td>\n",
       "      <td>0.311111</td>\n",
       "      <td>0.297222</td>\n",
       "      <td>0.3650</td>\n",
       "      <td>0.348371</td>\n",
       "      <td>0.049465</td>\n",
       "      <td>...</td>\n",
       "      <td>0.338205</td>\n",
       "      <td>0.322222</td>\n",
       "      <td>0.000349</td>\n",
       "      <td>0.079098</td>\n",
       "      <td>0.002012</td>\n",
       "      <td>0.000404</td>\n",
       "      <td>0.374979</td>\n",
       "      <td>-0.273501</td>\n",
       "      <td>0.318875</td>\n",
       "      <td>0.145182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>244</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.431877</td>\n",
       "      <td>0.4100</td>\n",
       "      <td>0.147651</td>\n",
       "      <td>0.096834</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.480556</td>\n",
       "      <td>0.5050</td>\n",
       "      <td>0.481203</td>\n",
       "      <td>0.033843</td>\n",
       "      <td>...</td>\n",
       "      <td>0.484864</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>-0.000050</td>\n",
       "      <td>0.100701</td>\n",
       "      <td>0.167965</td>\n",
       "      <td>0.000747</td>\n",
       "      <td>0.440430</td>\n",
       "      <td>-0.016335</td>\n",
       "      <td>0.473434</td>\n",
       "      <td>0.193096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>245</td>\n",
       "      <td>0.114583</td>\n",
       "      <td>0.421594</td>\n",
       "      <td>0.7875</td>\n",
       "      <td>0.174497</td>\n",
       "      <td>0.474860</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.636111</td>\n",
       "      <td>0.7775</td>\n",
       "      <td>0.739348</td>\n",
       "      <td>0.188891</td>\n",
       "      <td>...</td>\n",
       "      <td>0.720772</td>\n",
       "      <td>0.687302</td>\n",
       "      <td>-0.000417</td>\n",
       "      <td>0.100093</td>\n",
       "      <td>0.125973</td>\n",
       "      <td>0.001138</td>\n",
       "      <td>0.563832</td>\n",
       "      <td>-0.089779</td>\n",
       "      <td>0.700013</td>\n",
       "      <td>0.323749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>246</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.910026</td>\n",
       "      <td>0.7875</td>\n",
       "      <td>0.248322</td>\n",
       "      <td>0.474860</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.636111</td>\n",
       "      <td>0.7775</td>\n",
       "      <td>0.739348</td>\n",
       "      <td>0.188891</td>\n",
       "      <td>...</td>\n",
       "      <td>0.720772</td>\n",
       "      <td>0.687302</td>\n",
       "      <td>-0.000536</td>\n",
       "      <td>0.100893</td>\n",
       "      <td>0.499999</td>\n",
       "      <td>0.001435</td>\n",
       "      <td>0.715528</td>\n",
       "      <td>-0.181405</td>\n",
       "      <td>0.835001</td>\n",
       "      <td>0.522252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>247</td>\n",
       "      <td>0.258102</td>\n",
       "      <td>0.796915</td>\n",
       "      <td>0.5950</td>\n",
       "      <td>0.265101</td>\n",
       "      <td>0.163873</td>\n",
       "      <td>0.394444</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>0.5225</td>\n",
       "      <td>0.551378</td>\n",
       "      <td>0.191386</td>\n",
       "      <td>...</td>\n",
       "      <td>0.452505</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000961</td>\n",
       "      <td>0.102585</td>\n",
       "      <td>0.001567</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>0.604568</td>\n",
       "      <td>-0.738501</td>\n",
       "      <td>0.472639</td>\n",
       "      <td>0.393181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>248</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.676093</td>\n",
       "      <td>0.6900</td>\n",
       "      <td>0.489933</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.641667</td>\n",
       "      <td>0.641667</td>\n",
       "      <td>0.7375</td>\n",
       "      <td>0.739348</td>\n",
       "      <td>0.239213</td>\n",
       "      <td>...</td>\n",
       "      <td>0.687370</td>\n",
       "      <td>0.717460</td>\n",
       "      <td>-0.000116</td>\n",
       "      <td>0.141129</td>\n",
       "      <td>0.500484</td>\n",
       "      <td>0.001097</td>\n",
       "      <td>0.648457</td>\n",
       "      <td>-0.124471</td>\n",
       "      <td>0.615610</td>\n",
       "      <td>0.422904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>249 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Slope_minmax  PeakVal1_error  PeakVal2_error  PeakHt1_error  \\\n",
       "0        0.223958        0.786632          0.6925       0.379195   \n",
       "1        0.181818        0.370180          0.5000       0.197987   \n",
       "2        0.193182        0.519280          0.4700       0.308725   \n",
       "3        0.245536        0.383033          0.5350       0.305369   \n",
       "4        0.100216        0.336761          0.4000       0.171141   \n",
       "..            ...             ...             ...            ...   \n",
       "244      0.000000        0.431877          0.4100       0.147651   \n",
       "245      0.114583        0.421594          0.7875       0.174497   \n",
       "246      0.000000        0.910026          0.7875       0.248322   \n",
       "247      0.258102        0.796915          0.5950       0.265101   \n",
       "248      1.000000        0.676093          0.6900       0.489933   \n",
       "\n",
       "     PeakHt2_error  Min1_window  Min2_window  Max1_window  Max2_window  \\\n",
       "0         0.418994     0.672222     0.663889       0.7300     0.726817   \n",
       "1         0.242086     0.419444     0.391667       0.4900     0.466165   \n",
       "2         0.275605     0.250000     0.230556       0.3975     0.358396   \n",
       "3         0.175047     0.341667     0.327778       0.4225     0.403509   \n",
       "4         0.100559     0.311111     0.297222       0.3650     0.348371   \n",
       "..             ...          ...          ...          ...          ...   \n",
       "244       0.096834     0.483333     0.480556       0.5050     0.481203   \n",
       "245       0.474860     0.675000     0.636111       0.7775     0.739348   \n",
       "246       0.474860     0.675000     0.636111       0.7775     0.739348   \n",
       "247       0.163873     0.394444     0.425000       0.5225     0.551378   \n",
       "248       1.000000     0.641667     0.641667       0.7375     0.739348   \n",
       "\n",
       "     Var1_window  ...  Mean1_window  Mean2_window  Sig_coef1  Sig_coef2  \\\n",
       "0       0.151981  ...      0.702505      0.684127  -0.000179   0.157098   \n",
       "1       0.091495  ...      0.451461      0.428571  -0.000178   0.105077   \n",
       "2       0.190450  ...      0.328288      0.292593   0.000544   0.101382   \n",
       "3       0.098461  ...      0.382568      0.360847   0.000301   0.147579   \n",
       "4       0.049465  ...      0.338205      0.322222   0.000349   0.079098   \n",
       "..           ...  ...           ...           ...        ...        ...   \n",
       "244     0.033843  ...      0.484864      0.476190  -0.000050   0.100701   \n",
       "245     0.188891  ...      0.720772      0.687302  -0.000417   0.100093   \n",
       "246     0.188891  ...      0.720772      0.687302  -0.000536   0.100893   \n",
       "247     0.191386  ...      0.452505      0.500000   0.000961   0.102585   \n",
       "248     0.239213  ...      0.687370      0.717460  -0.000116   0.141129   \n",
       "\n",
       "     Sig_coef3  Sig_coef4   Max_fft   Min_fft  Mean_fft   Var_fft  \n",
       "0     0.005127   0.001196  0.704449 -0.305146  0.634014  0.501904  \n",
       "1     0.499994   0.000705  0.377450 -0.368154  0.351433  0.148848  \n",
       "2     0.003870   0.000346  0.376598 -0.543992  0.284399  0.155170  \n",
       "3     0.124742   0.000625  0.433015 -0.226763  0.418339  0.191966  \n",
       "4     0.002012   0.000404  0.374979 -0.273501  0.318875  0.145182  \n",
       "..         ...        ...       ...       ...       ...       ...  \n",
       "244   0.167965   0.000747  0.440430 -0.016335  0.473434  0.193096  \n",
       "245   0.125973   0.001138  0.563832 -0.089779  0.700013  0.323749  \n",
       "246   0.499999   0.001435  0.715528 -0.181405  0.835001  0.522252  \n",
       "247   0.001567   0.000517  0.604568 -0.738501  0.472639  0.393181  \n",
       "248   0.500484   0.001097  0.648457 -0.124471  0.615610  0.422904  \n",
       "\n",
       "[249 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Slope_minmax</th>\n",
       "      <th>PeakVal1_error</th>\n",
       "      <th>PeakVal2_error</th>\n",
       "      <th>PeakHt1_error</th>\n",
       "      <th>PeakHt2_error</th>\n",
       "      <th>Min1_window</th>\n",
       "      <th>Min2_window</th>\n",
       "      <th>Max1_window</th>\n",
       "      <th>Max2_window</th>\n",
       "      <th>Var1_window</th>\n",
       "      <th>...</th>\n",
       "      <th>Mean1_window</th>\n",
       "      <th>Mean2_window</th>\n",
       "      <th>Sig_coef1</th>\n",
       "      <th>Sig_coef2</th>\n",
       "      <th>Sig_coef3</th>\n",
       "      <th>Sig_coef4</th>\n",
       "      <th>Max_fft</th>\n",
       "      <th>Min_fft</th>\n",
       "      <th>Mean_fft</th>\n",
       "      <th>Var_fft</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.144231</td>\n",
       "      <td>0.501285</td>\n",
       "      <td>0.3575</td>\n",
       "      <td>0.154362</td>\n",
       "      <td>0.093110</td>\n",
       "      <td>0.447222</td>\n",
       "      <td>0.461111</td>\n",
       "      <td>0.4725</td>\n",
       "      <td>0.488722</td>\n",
       "      <td>0.034883</td>\n",
       "      <td>...</td>\n",
       "      <td>0.456159</td>\n",
       "      <td>0.480423</td>\n",
       "      <td>0.000627</td>\n",
       "      <td>0.108393</td>\n",
       "      <td>0.001025</td>\n",
       "      <td>0.000377</td>\n",
       "      <td>0.390830</td>\n",
       "      <td>-0.348937</td>\n",
       "      <td>0.337304</td>\n",
       "      <td>0.165106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.043750</td>\n",
       "      <td>0.228792</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.204698</td>\n",
       "      <td>0.232775</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.2625</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.013334</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251566</td>\n",
       "      <td>0.261905</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.056948</td>\n",
       "      <td>0.000748</td>\n",
       "      <td>0.000317</td>\n",
       "      <td>0.227373</td>\n",
       "      <td>-0.045013</td>\n",
       "      <td>0.223039</td>\n",
       "      <td>0.053624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.035511</td>\n",
       "      <td>0.221080</td>\n",
       "      <td>0.2350</td>\n",
       "      <td>0.144295</td>\n",
       "      <td>0.093110</td>\n",
       "      <td>0.205556</td>\n",
       "      <td>0.211111</td>\n",
       "      <td>0.2150</td>\n",
       "      <td>0.218045</td>\n",
       "      <td>0.006290</td>\n",
       "      <td>...</td>\n",
       "      <td>0.208246</td>\n",
       "      <td>0.217989</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>0.021526</td>\n",
       "      <td>0.000920</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>0.216550</td>\n",
       "      <td>-0.055635</td>\n",
       "      <td>0.207839</td>\n",
       "      <td>0.048761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.275064</td>\n",
       "      <td>0.2350</td>\n",
       "      <td>0.137584</td>\n",
       "      <td>0.229050</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.305556</td>\n",
       "      <td>0.3550</td>\n",
       "      <td>0.370927</td>\n",
       "      <td>0.072390</td>\n",
       "      <td>...</td>\n",
       "      <td>0.313152</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>-0.000035</td>\n",
       "      <td>0.247183</td>\n",
       "      <td>0.249993</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>0.277314</td>\n",
       "      <td>-0.029355</td>\n",
       "      <td>0.332700</td>\n",
       "      <td>0.079420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.380463</td>\n",
       "      <td>0.6275</td>\n",
       "      <td>0.164430</td>\n",
       "      <td>0.290503</td>\n",
       "      <td>0.558333</td>\n",
       "      <td>0.536111</td>\n",
       "      <td>0.6175</td>\n",
       "      <td>0.601504</td>\n",
       "      <td>0.098383</td>\n",
       "      <td>...</td>\n",
       "      <td>0.587161</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>-0.000273</td>\n",
       "      <td>0.980133</td>\n",
       "      <td>0.249876</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>0.442986</td>\n",
       "      <td>-0.055481</td>\n",
       "      <td>0.543379</td>\n",
       "      <td>0.204876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.222656</td>\n",
       "      <td>0.562982</td>\n",
       "      <td>0.5600</td>\n",
       "      <td>0.419463</td>\n",
       "      <td>0.391061</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.552778</td>\n",
       "      <td>0.6175</td>\n",
       "      <td>0.598997</td>\n",
       "      <td>0.083775</td>\n",
       "      <td>...</td>\n",
       "      <td>0.588727</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>0.149809</td>\n",
       "      <td>0.014424</td>\n",
       "      <td>0.000924</td>\n",
       "      <td>0.565877</td>\n",
       "      <td>-0.091022</td>\n",
       "      <td>0.569134</td>\n",
       "      <td>0.331637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>241</td>\n",
       "      <td>0.142241</td>\n",
       "      <td>0.455013</td>\n",
       "      <td>0.5125</td>\n",
       "      <td>0.362416</td>\n",
       "      <td>0.420857</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.5475</td>\n",
       "      <td>0.538847</td>\n",
       "      <td>0.145482</td>\n",
       "      <td>...</td>\n",
       "      <td>0.512004</td>\n",
       "      <td>0.495238</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.522328</td>\n",
       "      <td>-0.240149</td>\n",
       "      <td>0.479270</td>\n",
       "      <td>0.287802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>242</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.334190</td>\n",
       "      <td>0.3550</td>\n",
       "      <td>0.161074</td>\n",
       "      <td>0.121043</td>\n",
       "      <td>0.308333</td>\n",
       "      <td>0.313889</td>\n",
       "      <td>0.3250</td>\n",
       "      <td>0.335840</td>\n",
       "      <td>0.018507</td>\n",
       "      <td>...</td>\n",
       "      <td>0.315240</td>\n",
       "      <td>0.331746</td>\n",
       "      <td>0.611069</td>\n",
       "      <td>-0.186050</td>\n",
       "      <td>0.249984</td>\n",
       "      <td>-0.611593</td>\n",
       "      <td>0.319584</td>\n",
       "      <td>-0.017950</td>\n",
       "      <td>0.353250</td>\n",
       "      <td>0.105370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>243</td>\n",
       "      <td>0.200521</td>\n",
       "      <td>0.544987</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.224832</td>\n",
       "      <td>0.202980</td>\n",
       "      <td>0.397222</td>\n",
       "      <td>0.372222</td>\n",
       "      <td>0.4725</td>\n",
       "      <td>0.446115</td>\n",
       "      <td>0.084555</td>\n",
       "      <td>...</td>\n",
       "      <td>0.434760</td>\n",
       "      <td>0.411640</td>\n",
       "      <td>0.010025</td>\n",
       "      <td>-0.172258</td>\n",
       "      <td>0.000601</td>\n",
       "      <td>-0.008907</td>\n",
       "      <td>0.525652</td>\n",
       "      <td>-0.323542</td>\n",
       "      <td>0.417438</td>\n",
       "      <td>0.295973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>244</td>\n",
       "      <td>0.130208</td>\n",
       "      <td>0.622108</td>\n",
       "      <td>0.7300</td>\n",
       "      <td>0.328859</td>\n",
       "      <td>0.182495</td>\n",
       "      <td>0.627778</td>\n",
       "      <td>0.619444</td>\n",
       "      <td>0.6450</td>\n",
       "      <td>0.636591</td>\n",
       "      <td>0.049075</td>\n",
       "      <td>...</td>\n",
       "      <td>0.632568</td>\n",
       "      <td>0.622751</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>0.051904</td>\n",
       "      <td>0.003595</td>\n",
       "      <td>0.000973</td>\n",
       "      <td>0.679905</td>\n",
       "      <td>-0.184297</td>\n",
       "      <td>0.631070</td>\n",
       "      <td>0.481748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>245 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Slope_minmax  PeakVal1_error  PeakVal2_error  PeakHt1_error  \\\n",
       "0        0.144231        0.501285          0.3575       0.154362   \n",
       "1        0.043750        0.228792          0.2575       0.204698   \n",
       "2        0.035511        0.221080          0.2350       0.144295   \n",
       "3        0.062500        0.275064          0.2350       0.137584   \n",
       "4        0.187500        0.380463          0.6275       0.164430   \n",
       "..            ...             ...             ...            ...   \n",
       "240      0.222656        0.562982          0.5600       0.419463   \n",
       "241      0.142241        0.455013          0.5125       0.362416   \n",
       "242      0.250000        0.334190          0.3550       0.161074   \n",
       "243      0.200521        0.544987          0.5625       0.224832   \n",
       "244      0.130208        0.622108          0.7300       0.328859   \n",
       "\n",
       "     PeakHt2_error  Min1_window  Min2_window  Max1_window  Max2_window  \\\n",
       "0         0.093110     0.447222     0.461111       0.4725     0.488722   \n",
       "1         0.232775     0.250000     0.250000       0.2625     0.263158   \n",
       "2         0.093110     0.205556     0.211111       0.2150     0.218045   \n",
       "3         0.229050     0.277778     0.305556       0.3550     0.370927   \n",
       "4         0.290503     0.558333     0.536111       0.6175     0.601504   \n",
       "..             ...          ...          ...          ...          ...   \n",
       "240       0.391061     0.566667     0.552778       0.6175     0.598997   \n",
       "241       0.420857     0.466667     0.466667       0.5475     0.538847   \n",
       "242       0.121043     0.308333     0.313889       0.3250     0.335840   \n",
       "243       0.202980     0.397222     0.372222       0.4725     0.446115   \n",
       "244       0.182495     0.627778     0.619444       0.6450     0.636591   \n",
       "\n",
       "     Var1_window  ...  Mean1_window  Mean2_window  Sig_coef1  Sig_coef2  \\\n",
       "0       0.034883  ...      0.456159      0.480423   0.000627   0.108393   \n",
       "1       0.013334  ...      0.251566      0.261905   0.000106   0.056948   \n",
       "2       0.006290  ...      0.208246      0.217989   0.000164   0.021526   \n",
       "3       0.072390  ...      0.313152      0.342857  -0.000035   0.247183   \n",
       "4       0.098383  ...      0.587161      0.566667  -0.000273   0.980133   \n",
       "..           ...  ...           ...           ...        ...        ...   \n",
       "240     0.083775  ...      0.588727      0.571429   0.000141   0.149809   \n",
       "241     0.145482  ...      0.512004      0.495238   0.000000   0.000000   \n",
       "242     0.018507  ...      0.315240      0.331746   0.611069  -0.186050   \n",
       "243     0.084555  ...      0.434760      0.411640   0.010025  -0.172258   \n",
       "244     0.049075  ...      0.632568      0.622751   0.000246   0.051904   \n",
       "\n",
       "     Sig_coef3  Sig_coef4   Max_fft   Min_fft  Mean_fft   Var_fft  \n",
       "0     0.001025   0.000377  0.390830 -0.348937  0.337304  0.165106  \n",
       "1     0.000748   0.000317  0.227373 -0.045013  0.223039  0.053624  \n",
       "2     0.000920   0.000238  0.216550 -0.055635  0.207839  0.048761  \n",
       "3     0.249993   0.000470  0.277314 -0.029355  0.332700  0.079420  \n",
       "4     0.249876   0.000750  0.442986 -0.055481  0.543379  0.204876  \n",
       "..         ...        ...       ...       ...       ...       ...  \n",
       "240   0.014424   0.000924  0.565877 -0.091022  0.569134  0.331637  \n",
       "241   0.000000   0.000000  0.522328 -0.240149  0.479270  0.287802  \n",
       "242   0.249984  -0.611593  0.319584 -0.017950  0.353250  0.105370  \n",
       "243   0.000601  -0.008907  0.525652 -0.323542  0.417438  0.295973  \n",
       "244   0.003595   0.000973  0.679905 -0.184297  0.631070  0.481748  \n",
       "\n",
       "[245 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cgmData = pd.read_csv(\"ComparisonData/mealData\" + str(1) + '.csv', names=list(range(50)))\n",
    "for i in file_no[1:]:\n",
    "    cgm = pd.read_csv(\"ComparisonData/mealData\" + str(i) + '.csv', names=list(range(50)))\n",
    "    cgmData = cgmData.append(cgm)\n",
    "cgmData = cgmData.dropna(axis='columns', how='all')\n",
    "cgmData = cgmData.mask(cgmData.eq(-1)).ffill(axis=1)\n",
    "cgmData = cgmData.mask(cgmData.eq(-1)).bfill(axis=1)\n",
    "\n",
    "zero_entries = cgmData.isna().any(axis=1)\n",
    "cgmData = cgmData[zero_entries == False]\n",
    "\n",
    "cgmValues_np = cgmData.values\n",
    "cgmNorm_np = cgmValues_np/400.0\n",
    "\n",
    "length = len(cgmNorm_np[0])\n",
    "cgmSeries_np = [0.0833*(length-i-1) for i in range(0, length)]\n",
    "cgmSeries_np = np.array(cgmSeries_np)\n",
    "features = MergedFeatures(cgmNorm_np, cgmSeries_np)\n",
    "features_df = GenerateDF(features, COLUMNS)\n",
    "max_scale = features_df.abs().max(axis=0)\n",
    "max_scale.to_pickle('DataScale.pkl')\n",
    "normal_df = NormalizeDF(features_df, COLUMNS, max_scale)\n",
    "display(normal_df)\n",
    "normal_df.to_csv('MealFeatures.csv', index=False)\n",
    "\n",
    "cgmData = pd.read_csv(\"ComparisonData/Nomeal\" + str(1) + '.csv', names=list(range(50)))\n",
    "for i in file_no[1:]:\n",
    "    cgm = pd.read_csv(\"ComparisonData/Nomeal\" + str(i) + '.csv', names=list(range(50)))\n",
    "    cgmData = cgmData.append(cgm)\n",
    "cgmData = cgmData.dropna(axis='columns', how='all')\n",
    "cgmData = cgmData.mask(cgmData.eq(-1)).ffill(axis=1)\n",
    "cgmData = cgmData.mask(cgmData.eq(-1)).bfill(axis=1)\n",
    "\n",
    "zero_entries = cgmData.isna().any(axis=1)\n",
    "cgmData = cgmData[zero_entries == False]\n",
    "\n",
    "cgmValues_np = cgmData.values\n",
    "cgmNorm_np = cgmValues_np/400.0\n",
    "\n",
    "length = len(cgmNorm_np[0])\n",
    "cgmSeries_np = [0.0833*(length-i-1) for i in range(0, length)]\n",
    "cgmSeries_np = np.array(cgmSeries_np)\n",
    "features = MergedFeatures(cgmNorm_np, cgmSeries_np)\n",
    "features_df = GenerateDF(features, COLUMNS)\n",
    "normal_df = NormalizeDF(features_df, COLUMNS, max_scale)\n",
    "display(normal_df)\n",
    "normal_df.to_csv('NoMealFeatures.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. PCA Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCA_filename = 'PCA.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GeneratePCA(data, PCA_filename):\n",
    "    pca = PCA(n_components=5)\n",
    "    pca.fit(data)\n",
    "    components = pca.components_\n",
    "    variances = pca.explained_variance_\n",
    "    x = [i for i in range(0, len(components[0]))]\n",
    "    for i in range(0, 5):\n",
    "        plt.figure()\n",
    "        plt.bar(x, components[i])\n",
    "        plt.xticks(np.arange(len(components[0])), x, rotation=90)\n",
    "        plt.show()\n",
    "        positives = np.array(np.argwhere(components[i] > 0).flatten())\n",
    "        positive_sorted = np.argsort(components[i][:])\n",
    "    PCA_file = open(PCA_filename, 'wb')\n",
    "    pickle.dump(pca, PCA_file)\n",
    "    PCA_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Transform(data, PCA_filename):\n",
    "    PCA_file = open(PCA_filename, 'rb')\n",
    "    pca = pickle.load(PCA_file)\n",
    "    PCA_file.close()\n",
    "    return pca.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mealData = pd.read_csv('MealFeatures.csv')\n",
    "noMealData = pd.read_csv('NoMealFeatures.csv')\n",
    "\n",
    "GeneratePCA(mealData, PCA_filename)\n",
    "mealTransform = Transform(mealData, PCA_filename)\n",
    "noMealTransform = Transform(noMealData, PCA_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mealLabels = np.ones((mealTransform.shape[0], 1))\n",
    "noMealLabels = np.zeros((noMealTransform.shape[0], 1))\n",
    "\n",
    "mealDataWithLabels = np.concatenate((mealTransform, mealLabels), axis=1)\n",
    "noMealDataWithLabels = np.concatenate((noMealTransform, noMealLabels), axis=1)\n",
    "\n",
    "dataset = np.concatenate((mealDataWithLabels, noMealDataWithLabels), axis=0)\n",
    "np.random.shuffle(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Training Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifiers:\n",
    "    def __init__(self):\n",
    "        self.Anirudh_filename = 'Anirudh.pkl'\n",
    "        self.Omkar_filename = 'Omkar.pkl'\n",
    "        self.Ananth_filename = 'Ananth.pkl'\n",
    "        self.Vedant_filename = 'Vedant.pkl'\n",
    "        return\n",
    "    \n",
    "    def genClassifier_Anirudh(self):\n",
    "        self.Anirudh_SVM = SVC(C=1.0, kernel='rbf', gamma='scale', probability=True)\n",
    "        self.Anirudh_KNN = KNeighborsClassifier(n_neighbors=5, weights='distance', p=2)\n",
    "        self.Anirudh_classifier = VotingClassifier(estimators=[('SVM', self.Anirudh_SVM), ('KNN', self.Anirudh_KNN)], voting='soft')\n",
    "          \n",
    "    def genClassifier_Vedant(self):\n",
    "        kernel = 1.0 * RBF(1.0)\n",
    "        self.Vedant_gpc = GaussianProcessClassifier(kernel=kernel,random_state=0)\n",
    "        self.Vedant_mlp = MLPClassifier(solver='lbfgs',activation ='tanh', alpha=1e-5,hidden_layer_sizes=(4,2), random_state=1)\n",
    "        self.Vedant_classifier = VotingClassifier(estimators=[('gpc', self.Vedant_gpc), ('mlp', self.Vedant_mlp)],voting='soft')\n",
    "\n",
    "    def genClassifier_Omkar(self):\n",
    "        self.Omkar_rf1 = RandomForestClassifier(n_estimators=50, max_depth=6,random_state=0)#.fit(dataset[train][:, :-1], dataset[train][:, -1])\n",
    "        self.Omkar_rf2 = AdaBoostClassifier(n_estimators=50, random_state=0)#.fit(dataset[train][:, :-1], dataset[train][:, -1])\n",
    "        kernel = 1.0 * RBF(1.0)\n",
    "        self.Omkar_rf3 = GaussianProcessClassifier(kernel=kernel,random_state=0)#.fit(dataset[train][:, :-1], dataset[train][:, -1])\n",
    "        self.Omkar_rf4 = SVC(kernel='rbf', gamma='auto')#.fit(dataset[train][:, :-1], dataset[train][:, -1])\n",
    "\n",
    "        self.Omkar_classifier = VotingClassifier(estimators=[('rf', self.Omkar_rf1), ('ab', self.Omkar_rf2), ('gpc', self.Omkar_rf3), ('svm',self.Omkar_rf4)], voting='hard', weights=[2,0.9,0.5,0.3])\n",
    "\n",
    "    def genClassifier_Ananth(self):\n",
    "        self.Ananth_dt=DecisionTreeClassifier(max_depth=5)\n",
    "        self.Ananth_gnb=GaussianNB()\n",
    "        self.Ananth_classifier = VotingClassifier(estimators=[('dt',self.Ananth_dt), ('gnb',self.Ananth_gnb)],voting='soft')\n",
    "        \n",
    "    def trainClassifier_Anirudh(self, train_data):\n",
    "        self.genClassifier_Anirudh()\n",
    "        self.Anirudh_classifier.fit(train_data[:, :-1], train_data[:, -1])\n",
    "        \n",
    "    def trainClassifier_Vedant(self, train_data):\n",
    "        self.genClassifier_Vedant()\n",
    "        self.Vedant_classifier.fit(train_data[:, :-1], train_data[:, -1])\n",
    "        \n",
    "    def trainClassifier_Omkar(self, train_data):\n",
    "        self.genClassifier_Omkar()\n",
    "        self.Omkar_classifier.fit(train_data[:, :-1], train_data[:, -1])\n",
    "        \n",
    "    def trainClassifier_Ananth(self, train_data):\n",
    "        self.genClassifier_Ananth()\n",
    "        self.Ananth_classifier.fit(train_data[:, :-1], train_data[:, -1])\n",
    "        \n",
    "    def validateClassifier_Anirudh(self, test_data):\n",
    "        labels = self.Anirudh_classifier.predict(test_data[:, :-1])\n",
    "        return labels\n",
    "    \n",
    "    def validateClassifier_Vedant(self, test_data):\n",
    "        labels = self.Vedant_classifier.predict(test_data[:, :-1])\n",
    "        return labels\n",
    "    \n",
    "    def validateClassifier_Omkar(self, test_data):\n",
    "        labels = self.Omkar_classifier.predict(test_data[:, :-1])\n",
    "        return labels\n",
    "    \n",
    "    def validateClassifier_Ananth(self, test_data):\n",
    "        labels = self.Ananth_classifier.predict(test_data[:, :-1])\n",
    "        return labels\n",
    "    \n",
    "    def loadClassifier_Anirudh(self):\n",
    "        save_file = open(self.Anirudh_filename, 'rb')\n",
    "        self.Anirudh_classifier = pickle.load(save_file)\n",
    "        save_file.close()\n",
    "        return\n",
    "    \n",
    "    def loadClassifier_Vedant(self):\n",
    "        save_file = open(self.Vedant_filename, 'rb')\n",
    "        self.Vedant_classifier = pickle.load(save_file)\n",
    "        save_file.close()\n",
    "        return\n",
    "    \n",
    "    def loadClassifier_Omkar(self):\n",
    "        save_file = open(self.Omkar_filename, 'rb')\n",
    "        self.Omkar_classifier = pickle.load(save_file)\n",
    "        save_file.close()\n",
    "        return\n",
    "    \n",
    "    def loadClassifier_Ananth(self):\n",
    "        save_file = open(self.Ananth_filename, 'rb')\n",
    "        self.Ananth_classifier = pickle.load(save_file)\n",
    "        save_file.close()\n",
    "        return\n",
    "    \n",
    "    def loadAllClassifiers():\n",
    "        self.loadClassifier_Anirudh()\n",
    "        self.loadClassifier_Vedant()\n",
    "        self.loadClassifier_Omkar()\n",
    "        self.loadClassifier_Ananth()\n",
    "        \n",
    "    def saveClassifier_Anirudh(self):\n",
    "        save_file = open(self.Anirudh_filename, 'wb')\n",
    "        pickle.dump(self.Anirudh_classifier, save_file)\n",
    "        save_file.close()\n",
    "        return\n",
    "    \n",
    "    def saveClassifier_Vedant(self):\n",
    "        save_file = open(self.Vedant_filename, 'wb')\n",
    "        pickle.dump(self.Vedant_classifier, save_file)\n",
    "        save_file.close()\n",
    "        return\n",
    "    \n",
    "    def saveClassifier_Omkar(self):\n",
    "        save_file = open(self.Omkar_filename, 'wb')\n",
    "        pickle.dump(self.Omkar_classifier, save_file)\n",
    "        save_file.close()\n",
    "        return\n",
    "    \n",
    "    def saveClassifier_Ananth(self):\n",
    "        save_file = open(self.Ananth_filename, 'wb')\n",
    "        pickle.dump(self.Ananth_classifier, save_file)\n",
    "        save_file.close()\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(test_labels, labels):\n",
    "    TP = 0.0\n",
    "    FP = 0.0\n",
    "    TN = 0.0\n",
    "    FN = 0.0\n",
    "    base = len(labels)\n",
    "    for i in range(len(labels)):\n",
    "        if labels[i] == 1:\n",
    "            if test_labels[i] == 1:\n",
    "                TP += 1\n",
    "            else:\n",
    "                FP += 1\n",
    "        else:\n",
    "            if test_labels[i] == 0:\n",
    "                TN += 1\n",
    "            else:\n",
    "                FN += 1\n",
    "    acc = (TP+TN)/base\n",
    "    if TP+FP == 0:\n",
    "        prec = 1.0\n",
    "    else:\n",
    "        prec = (TP)/(TP+FP)\n",
    "    if TP+FN == 0:\n",
    "        rec = 1.0\n",
    "    else:\n",
    "        rec = (TP)/(TP+FN)\n",
    "    return acc, prec, rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############ Model 1 (Anirudh) ##############\n",
      "Acc = 0.760000, Prec = 0.750000, Rec = 0.807692, F1 = 0.777778\n",
      "Acc = 0.720000, Prec = 0.678571, Rec = 0.791667, F1 = 0.730769\n",
      "Acc = 0.760000, Prec = 0.615385, Rec = 0.888889, F1 = 0.727273\n",
      "Acc = 0.820000, Prec = 0.920000, Rec = 0.766667, F1 = 0.836364\n",
      "Acc = 0.836735, Prec = 0.766667, Rec = 0.958333, F1 = 0.851852\n",
      "Acc = 0.673469, Prec = 0.560000, Rec = 0.736842, F1 = 0.636364\n",
      "Acc = 0.714286, Prec = 0.814815, Rec = 0.709677, F1 = 0.758621\n",
      "Acc = 0.816327, Prec = 0.781250, Rec = 0.925926, F1 = 0.847458\n",
      "Acc = 0.775510, Prec = 0.724138, Rec = 0.875000, F1 = 0.792453\n",
      "Acc = 0.673469, Prec = 0.692308, Rec = 0.692308, F1 = 0.692308\n",
      "MEAN: Acc = 0.754980, Prec = 0.730313, Rec = 0.815300, F1 = 0.770470\n",
      "############ Model 2 (Vedant) ##############\n",
      "Acc = 0.760000, Prec = 0.791667, Rec = 0.730769, F1 = 0.760000\n",
      "Acc = 0.800000, Prec = 0.705882, Rec = 1.000000, F1 = 0.827586\n",
      "Acc = 0.820000, Prec = 0.680000, Rec = 0.944444, F1 = 0.790698\n",
      "Acc = 0.760000, Prec = 0.846154, Rec = 0.733333, F1 = 0.785714\n",
      "Acc = 0.877551, Prec = 0.821429, Rec = 0.958333, F1 = 0.884615\n",
      "Acc = 0.734694, Prec = 0.607143, Rec = 0.894737, F1 = 0.723404\n",
      "Acc = 0.755102, Prec = 0.851852, Rec = 0.741935, F1 = 0.793103\n",
      "Acc = 0.877551, Prec = 0.862069, Rec = 0.925926, F1 = 0.892857\n",
      "Acc = 0.795918, Prec = 0.718750, Rec = 0.958333, F1 = 0.821429\n",
      "Acc = 0.714286, Prec = 0.714286, Rec = 0.769231, F1 = 0.740741\n",
      "MEAN: Acc = 0.789510, Prec = 0.759923, Rec = 0.865704, F1 = 0.809372\n",
      "############ Model 3 (Omkar) ##############\n",
      "Acc = 0.760000, Prec = 0.818182, Rec = 0.692308, F1 = 0.750000\n",
      "Acc = 0.840000, Prec = 0.750000, Rec = 1.000000, F1 = 0.857143\n",
      "Acc = 0.760000, Prec = 0.615385, Rec = 0.888889, F1 = 0.727273\n",
      "Acc = 0.800000, Prec = 0.857143, Rec = 0.800000, F1 = 0.827586\n",
      "Acc = 0.857143, Prec = 0.793103, Rec = 0.958333, F1 = 0.867925\n",
      "Acc = 0.734694, Prec = 0.607143, Rec = 0.894737, F1 = 0.723404\n",
      "Acc = 0.714286, Prec = 0.840000, Rec = 0.677419, F1 = 0.750000\n",
      "Acc = 0.918367, Prec = 0.896552, Rec = 0.962963, F1 = 0.928571\n",
      "Acc = 0.775510, Prec = 0.724138, Rec = 0.875000, F1 = 0.792453\n",
      "Acc = 0.673469, Prec = 0.666667, Rec = 0.769231, F1 = 0.714286\n",
      "MEAN: Acc = 0.783347, Prec = 0.756831, Rec = 0.851888, F1 = 0.801551\n",
      "############ Model 4 (Ananth) ##############\n",
      "Acc = 0.720000, Prec = 0.730769, Rec = 0.730769, F1 = 0.730769\n",
      "Acc = 0.600000, Prec = 0.555556, Rec = 0.833333, F1 = 0.666667\n",
      "Acc = 0.740000, Prec = 0.586207, Rec = 0.944444, F1 = 0.723404\n",
      "Acc = 0.880000, Prec = 0.852941, Rec = 0.966667, F1 = 0.906250\n",
      "Acc = 0.775510, Prec = 0.685714, Rec = 1.000000, F1 = 0.813559\n",
      "Acc = 0.673469, Prec = 0.542857, Rec = 1.000000, F1 = 0.703704\n",
      "Acc = 0.734694, Prec = 0.781250, Rec = 0.806452, F1 = 0.793651\n",
      "Acc = 0.836735, Prec = 0.771429, Rec = 1.000000, F1 = 0.870968\n",
      "Acc = 0.693878, Prec = 0.615385, Rec = 1.000000, F1 = 0.761905\n",
      "Acc = 0.673469, Prec = 0.638889, Rec = 0.884615, F1 = 0.741935\n",
      "MEAN: Acc = 0.732776, Prec = 0.676100, Rec = 0.916628, F1 = 0.778202\n"
     ]
    }
   ],
   "source": [
    "no_k = 10\n",
    "kf = KFold(no_k)\n",
    "total_acc = 0.0\n",
    "max_acc = 0.0\n",
    "total_prec = 0.0\n",
    "total_rec = 0.0\n",
    "models = Classifiers()\n",
    "\n",
    "print(\"############ Model 1 (Anirudh) ##############\")\n",
    "for train, test in kf.split(dataset):\n",
    "    models.trainClassifier_Anirudh(dataset[train])\n",
    "    labels = models.validateClassifier_Anirudh(dataset[test])\n",
    "    acc, prec, rec = evaluate(dataset[test][:, -1], labels)\n",
    "    max_acc = max(max_acc, acc)\n",
    "    if max_acc == acc:\n",
    "        models.saveClassifier_Anirudh()\n",
    "    total_acc += acc\n",
    "    total_prec += prec\n",
    "    total_rec += rec\n",
    "    print(\"Acc = %f, Prec = %f, Rec = %f, F1 = %f\" %(acc, prec, rec, 2*prec*rec/(prec+rec)))\n",
    "print(\"MEAN: Acc = %f, Prec = %f, Rec = %f, F1 = %f\" %(total_acc/no_k, total_prec/no_k, total_rec/no_k, 2*total_prec*total_rec/(no_k*(total_prec+total_rec))))\n",
    "\n",
    "total_acc = 0.0\n",
    "max_acc = 0.0\n",
    "total_prec = 0.0\n",
    "total_rec = 0.0\n",
    "print(\"############ Model 2 (Vedant) ##############\")\n",
    "for train, test in kf.split(dataset):\n",
    "    models.trainClassifier_Vedant(dataset[train])\n",
    "    labels = models.validateClassifier_Vedant(dataset[test])\n",
    "    acc, prec, rec = evaluate(dataset[test][:, -1], labels)\n",
    "    max_acc = max(max_acc, acc)\n",
    "    if max_acc == acc:\n",
    "        models.saveClassifier_Vedant()\n",
    "    total_acc += acc\n",
    "    total_prec += prec\n",
    "    total_rec += rec\n",
    "    print(\"Acc = %f, Prec = %f, Rec = %f, F1 = %f\" %(acc, prec, rec, 2*prec*rec/(prec+rec)))\n",
    "print(\"MEAN: Acc = %f, Prec = %f, Rec = %f, F1 = %f\" %(total_acc/no_k, total_prec/no_k, total_rec/no_k, 2*total_prec*total_rec/(no_k*(total_prec+total_rec))))\n",
    "\n",
    "total_acc = 0.0\n",
    "max_acc = 0.0\n",
    "total_prec = 0.0\n",
    "total_rec = 0.0\n",
    "print(\"############ Model 3 (Omkar) ##############\")\n",
    "for train, test in kf.split(dataset):\n",
    "    models.trainClassifier_Omkar(dataset[train])\n",
    "    labels = models.validateClassifier_Omkar(dataset[test])\n",
    "    acc, prec, rec = evaluate(dataset[test][:, -1], labels)\n",
    "    max_acc = max(max_acc, acc)\n",
    "    if max_acc == acc:\n",
    "        models.saveClassifier_Omkar()\n",
    "    total_acc += acc\n",
    "    total_prec += prec\n",
    "    total_rec += rec\n",
    "    print(\"Acc = %f, Prec = %f, Rec = %f, F1 = %f\" %(acc, prec, rec, 2*prec*rec/(prec+rec)))\n",
    "print(\"MEAN: Acc = %f, Prec = %f, Rec = %f, F1 = %f\" %(total_acc/no_k, total_prec/no_k, total_rec/no_k, 2*total_prec*total_rec/(no_k*(total_prec+total_rec))))\n",
    "\n",
    "total_acc = 0.0\n",
    "max_acc = 0.0\n",
    "total_prec = 0.0\n",
    "total_rec = 0.0\n",
    "print(\"############ Model 4 (Ananth) ##############\")\n",
    "for train, test in kf.split(dataset):\n",
    "    models.trainClassifier_Ananth(dataset[train])\n",
    "    labels = models.validateClassifier_Ananth(dataset[test])\n",
    "    acc, prec, rec = evaluate(dataset[test][:, -1], labels)\n",
    "    max_acc = max(max_acc, acc)\n",
    "    if max_acc == acc:\n",
    "        models.saveClassifier_Ananth()\n",
    "    total_acc += acc\n",
    "    total_prec += prec\n",
    "    total_rec += rec\n",
    "    print(\"Acc = %f, Prec = %f, Rec = %f, F1 = %f\" %(acc, prec, rec, 2*prec*rec/(prec+rec)))\n",
    "print(\"MEAN: Acc = %f, Prec = %f, Rec = %f, F1 = %f\" %(total_acc/no_k, total_prec/no_k, total_rec/no_k, 2*total_prec*total_rec/(no_k*(total_prec+total_rec))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
