{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.preprocessing as pre\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from scipy.stats import linregress as lr\n",
    "from scipy.signal import find_peaks as find_peaks\n",
    "from scipy.fftpack import fft, ifft,rfft\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.optimize import curve_fit\n",
    "import pickle\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.svm import SVC, NuSVC, LinearSVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Feature Set Calculation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Globals\n",
    "COLUMNS = np.array(['Slope_minmax', \n",
    "           'PeakVal1_error', 'PeakVal2_error', 'PeakHt1_error', 'PeakHt2_error', \n",
    "           'Min1_window', 'Min2_window', 'Max1_window', 'Max2_window', 'Var1_window', 'Var2_window', 'Mean1_window', 'Mean2_window', \n",
    "           'Sig_coef1','Sig_coef2','Sig_coef3','Sig_coef4',\n",
    "           'Max_fft', 'Min_fft', 'Mean_fft', 'Var_fft'\n",
    "          ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CalcFeatureSet1(cgmNorm_np, cgmSeries_np):\n",
    "    maxs = np.argmax(cgmNorm_np, axis=1)\n",
    "    mins = [np.argmin(cgmNorm_np[i, maxs[i]:])+maxs[i] for i in range(len(maxs))]\n",
    "\n",
    "    slopes = []\n",
    "    time_diffs = []\n",
    "    for i in range(len(maxs)):\n",
    "        slope = (cgmNorm_np[i][maxs[i]]-cgmNorm_np[i][mins[i]])/(cgmSeries_np[maxs[i]]-cgmSeries_np[mins[i]])\n",
    "        time_diffs.append(cgmSeries_np[maxs[i]]-cgmSeries_np[mins[i]])\n",
    "        slopes.append(slope)\n",
    "\n",
    "    slopes = np.nan_to_num(slopes)\n",
    "    time_diffs = np.nan_to_num(time_diffs)\n",
    "    reg_window_size = 4\n",
    "    reg_errors = []\n",
    "    peak_values = []\n",
    "    peak_heights = []\n",
    "    peak_time_diffs = []\n",
    "    peak_times = []\n",
    "    for j in range(len(cgmNorm_np)):\n",
    "        errors = np.array([])\n",
    "        for i in range(len(cgmNorm_np[j])-reg_window_size):\n",
    "            times = cgmSeries_np[i:i+reg_window_size-1]\n",
    "            if np.isnan(times).any():\n",
    "                errors = np.append(errors, -1)\n",
    "                continue\n",
    "            coeffs = np.polyfit(times, cgmNorm_np[j][i:i+reg_window_size-1], 1)\n",
    "            poly = np.poly1d(coeffs)\n",
    "            error = poly(cgmSeries_np[i+reg_window_size])-cgmNorm_np[j][i+reg_window_size];\n",
    "            errors = np.append(errors, error)\n",
    "        peaks, height_dict = find_peaks(errors, height = 0)\n",
    "        heights = height_dict['peak_heights']\n",
    "        sorted_args = heights.argsort()\n",
    "        peaks = peaks[sorted_args]\n",
    "        peaks = peaks[-2:]\n",
    "        heights = heights[sorted_args]\n",
    "        heights = heights[-2:]\n",
    "        values = cgmNorm_np[j][peaks+reg_window_size-1]\n",
    "        times1 = cgmSeries_np[peaks+reg_window_size]\n",
    "        times2 = cgmSeries_np[peaks+reg_window_size-1]\n",
    "        reg_errors.append(errors)\n",
    "        while(len(values) < 2):\n",
    "            values = np.append(values, 0)\n",
    "            heights = np.append(heights, 0)\n",
    "            times1 = np.append(times, 0)\n",
    "            times2 = np.append(times2, 0)\n",
    "        peak_values.append(values)\n",
    "        peak_heights.append(heights)\n",
    "        peak_time_diffs.append(times1)\n",
    "        peak_times.append(times2)\n",
    "    reg_errors = np.array(reg_errors)\n",
    "    matrix = []\n",
    "    for i in range(0, len(cgmNorm_np)):\n",
    "        matrix_row = np.array([])\n",
    "        matrix_row = np.append(matrix_row, slopes[i])\n",
    "#         matrix_row = np.append(matrix_row, time_diffs[i])\n",
    "        matrix_row = np.append(matrix_row, peak_values[i])\n",
    "        matrix_row = np.append(matrix_row, peak_heights[i])\n",
    "#         matrix_row = np.append(matrix_row, peak_times[i])\n",
    "        matrix.append(matrix_row)\n",
    "    matrix = np.array(matrix)\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CalcFeatureSet2(cgmNorm_np, cgmSeries_np):\n",
    "    window_mins = []\n",
    "    window_maxs = []\n",
    "    window_means = []\n",
    "    window_vars = []\n",
    "    for i in range(0, len(cgmNorm_np)):\n",
    "        window_input = DataFrame(cgmNorm_np[i][::-1])\n",
    "        width=5\n",
    "        shifted=window_input.shift(width - 1)\n",
    "        window=shifted.rolling(window=width)\n",
    "        dataframe=concat([window.var(), window.min(),  window.mean(), window.max() ], axis=1)\n",
    "        dataframe.columns = ['var', 'min', 'mean', 'max']\n",
    "        window_features = dataframe.nlargest(2,'var')\n",
    "        window_values = window_features.values\n",
    "        window_mins.append([window_values[0][1], window_values[1][1]])\n",
    "        window_maxs.append([window_values[0][3], window_values[1][3]])\n",
    "        window_vars.append([window_values[0][0], window_values[1][0]])\n",
    "        window_means.append([window_values[0][2], window_values[1][2]])\n",
    "    \n",
    "    matrix = []\n",
    "    for i in range(0, len(cgmNorm_np)):\n",
    "        matrix_row = np.array([])\n",
    "        matrix_row = np.append(matrix_row, window_mins[i])\n",
    "        matrix_row = np.append(matrix_row, window_maxs[i])\n",
    "        matrix_row = np.append(matrix_row, window_vars[i])\n",
    "        matrix_row = np.append(matrix_row, window_means[i])\n",
    "        matrix.append(matrix_row)\n",
    "    matrix = np.array(matrix)\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x, L ,x0, k, b):\n",
    "    y = L / (1 + np.exp(-k*(x-x0)))+b\n",
    "    return (y)\n",
    "\n",
    "def CalcFeatureSet3(cgmNorm_np, cgmSeries_np):\n",
    "    n_series = []\n",
    "    n_datenum = []\n",
    "    sig1 = []\n",
    "    sig2 = []\n",
    "    sig3 = []\n",
    "    sig4 = []\n",
    "    for i in range(0, len(cgmNorm_np)):\n",
    "        idx = np.isfinite(cgmSeries_np) & np.isfinite(cgmNorm_np[i])\n",
    "        n_series.append(cgmNorm_np[i][idx])  \n",
    "        n_datenum.append(cgmSeries_np[idx])\n",
    "    for i in range(0,len(cgmNorm_np)):\n",
    "        if(len(n_series[i]) !=0 ):\n",
    "            try:\n",
    "                p0 = [max(n_series[i]), np.median(n_datenum[i]),250,min(n_series[i])] \n",
    "                popt, pcov = curve_fit(sigmoid, n_datenum[i], n_series[i],p0,method='trf')\n",
    "            except: \n",
    "                popt=[0,0,0,0]\n",
    "\n",
    "            sig1.append(popt[0])\n",
    "            sig2.append(popt[1])\n",
    "            sig3.append(popt[2])\n",
    "            sig4.append(popt[3])\n",
    "    \n",
    "    matrix = []\n",
    "    for i in range(0, len(cgmNorm_np)):\n",
    "        matrix_row = np.array([])\n",
    "        matrix_row = np.append(matrix_row, sig1[i])\n",
    "        matrix_row = np.append(matrix_row, sig2[i])\n",
    "        matrix_row = np.append(matrix_row, sig3[i])\n",
    "        matrix_row = np.append(matrix_row, sig4[i])\n",
    "        matrix.append(matrix_row)\n",
    "    matrix = np.array(matrix)\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CalcFeatureSet4(cgmNorm_np, cgmSeries_np):\n",
    "    Feature_vector=[]\n",
    "    for i in range(0, len(cgmNorm_np)):\n",
    "    #FFT\n",
    "        fastfouriertransform=rfft(cgmNorm_np[i])\n",
    "        fft_max=np.nanmax(fastfouriertransform)\n",
    "        s=np.where(fastfouriertransform == fft_max)\n",
    "        fft_min=np.nanmin(fastfouriertransform)\n",
    "        s=np.where(fastfouriertransform == fft_min)\n",
    "        fft_mean=np.nanmean(fastfouriertransform)\n",
    "        fft_variance=np.nanvar(fastfouriertransform)\n",
    "        Feature_vector.append(np.array([fft_max,fft_min,fft_mean,fft_variance]))\n",
    "    matrix = np.array(Feature_vector)\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MergedFeatures(cgmNorm_np, cgmSeries_np):\n",
    "    feature_set_1 = CalcFeatureSet1(cgmNorm_np, cgmSeries_np)\n",
    "    feature_set_2 = CalcFeatureSet2(cgmNorm_np, cgmSeries_np)\n",
    "    feature_set_3 = CalcFeatureSet3(cgmNorm_np, cgmSeries_np)\n",
    "    feature_set_4 = CalcFeatureSet4(cgmNorm_np, cgmSeries_np)\n",
    "    features = np.concatenate((feature_set_1, feature_set_2), axis=1)\n",
    "    features = np.concatenate((features, feature_set_3), axis=1)\n",
    "    features = np.concatenate((features, feature_set_4), axis=1)\n",
    "    features = np.nan_to_num(features)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenerateDF(features, columns):\n",
    "    feature_df = pd.DataFrame(features, columns=columns)\n",
    "    return feature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NormalizeDF(feature_df, columns, max_scale):\n",
    "    for i in columns:\n",
    "        feature_df[i] = feature_df[i]/max_scale[i]\n",
    "    return feature_df\n",
    "#     means = feature_df.mean(axis=0)\n",
    "#     large_means = np.argwhere(means>1).flatten()\n",
    "#     small_means = np.argwhere(means<-1).flatten()\n",
    "#     for i in large_means:\n",
    "#         base = int(np.log10(means[i]))+1\n",
    "#         if base > 1:\n",
    "#             feature_df[columns[i]] = np.nan_to_num(np.log10(feature_df[columns[i]].replace(0, np.nan)))/base\n",
    "#     for i in small_means:\n",
    "#         base = int(np.log10(np.abs(means[i])))+1\n",
    "#         if base > 1:\n",
    "#             feature_df[columns[i]] = np.sign(feature_df[columns[i]])*np.nan_to_num(np.log10(np.abs(feature_df[columns[i]].replace(0, np.nan))))/base\n",
    "# #     print(large_means)\n",
    "#     return feature_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Calculating Feature Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Reading Meal Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_no = [1, 2, 3, 4, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\anant\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n",
      "c:\\users\\anant\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Slope_minmax</th>\n",
       "      <th>PeakVal1_error</th>\n",
       "      <th>PeakVal2_error</th>\n",
       "      <th>PeakHt1_error</th>\n",
       "      <th>PeakHt2_error</th>\n",
       "      <th>Min1_window</th>\n",
       "      <th>Min2_window</th>\n",
       "      <th>Max1_window</th>\n",
       "      <th>Max2_window</th>\n",
       "      <th>Var1_window</th>\n",
       "      <th>...</th>\n",
       "      <th>Mean1_window</th>\n",
       "      <th>Mean2_window</th>\n",
       "      <th>Sig_coef1</th>\n",
       "      <th>Sig_coef2</th>\n",
       "      <th>Sig_coef3</th>\n",
       "      <th>Sig_coef4</th>\n",
       "      <th>Max_fft</th>\n",
       "      <th>Min_fft</th>\n",
       "      <th>Mean_fft</th>\n",
       "      <th>Var_fft</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.223958</td>\n",
       "      <td>0.786632</td>\n",
       "      <td>0.6925</td>\n",
       "      <td>0.379195</td>\n",
       "      <td>0.418994</td>\n",
       "      <td>0.672222</td>\n",
       "      <td>0.663889</td>\n",
       "      <td>0.7300</td>\n",
       "      <td>0.726817</td>\n",
       "      <td>0.151981</td>\n",
       "      <td>...</td>\n",
       "      <td>0.702505</td>\n",
       "      <td>0.684127</td>\n",
       "      <td>-0.000191</td>\n",
       "      <td>0.156219</td>\n",
       "      <td>0.005126</td>\n",
       "      <td>0.001271</td>\n",
       "      <td>0.704449</td>\n",
       "      <td>-0.305146</td>\n",
       "      <td>0.634014</td>\n",
       "      <td>0.501904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.370180</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.197987</td>\n",
       "      <td>0.242086</td>\n",
       "      <td>0.419444</td>\n",
       "      <td>0.391667</td>\n",
       "      <td>0.4900</td>\n",
       "      <td>0.466165</td>\n",
       "      <td>0.091495</td>\n",
       "      <td>...</td>\n",
       "      <td>0.451461</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>-0.000341</td>\n",
       "      <td>0.140436</td>\n",
       "      <td>0.187519</td>\n",
       "      <td>0.000761</td>\n",
       "      <td>0.377450</td>\n",
       "      <td>-0.368154</td>\n",
       "      <td>0.351433</td>\n",
       "      <td>0.148848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.193182</td>\n",
       "      <td>0.519280</td>\n",
       "      <td>0.4700</td>\n",
       "      <td>0.308725</td>\n",
       "      <td>0.275605</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.230556</td>\n",
       "      <td>0.3975</td>\n",
       "      <td>0.358396</td>\n",
       "      <td>0.190450</td>\n",
       "      <td>...</td>\n",
       "      <td>0.328288</td>\n",
       "      <td>0.292593</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>0.100817</td>\n",
       "      <td>0.003870</td>\n",
       "      <td>0.000368</td>\n",
       "      <td>0.376598</td>\n",
       "      <td>-0.543992</td>\n",
       "      <td>0.284399</td>\n",
       "      <td>0.155170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.245536</td>\n",
       "      <td>0.383033</td>\n",
       "      <td>0.5350</td>\n",
       "      <td>0.305369</td>\n",
       "      <td>0.175047</td>\n",
       "      <td>0.341667</td>\n",
       "      <td>0.327778</td>\n",
       "      <td>0.4225</td>\n",
       "      <td>0.403509</td>\n",
       "      <td>0.098461</td>\n",
       "      <td>...</td>\n",
       "      <td>0.382568</td>\n",
       "      <td>0.360847</td>\n",
       "      <td>0.000320</td>\n",
       "      <td>0.146757</td>\n",
       "      <td>0.124742</td>\n",
       "      <td>0.000665</td>\n",
       "      <td>0.433015</td>\n",
       "      <td>-0.226763</td>\n",
       "      <td>0.418339</td>\n",
       "      <td>0.191966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.100216</td>\n",
       "      <td>0.336761</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.171141</td>\n",
       "      <td>0.100559</td>\n",
       "      <td>0.311111</td>\n",
       "      <td>0.297222</td>\n",
       "      <td>0.3650</td>\n",
       "      <td>0.348371</td>\n",
       "      <td>0.049465</td>\n",
       "      <td>...</td>\n",
       "      <td>0.338205</td>\n",
       "      <td>0.322222</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>0.078657</td>\n",
       "      <td>0.002012</td>\n",
       "      <td>0.000429</td>\n",
       "      <td>0.374979</td>\n",
       "      <td>-0.273501</td>\n",
       "      <td>0.318875</td>\n",
       "      <td>0.145182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>239</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.431877</td>\n",
       "      <td>0.4100</td>\n",
       "      <td>0.147651</td>\n",
       "      <td>0.096834</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.480556</td>\n",
       "      <td>0.5050</td>\n",
       "      <td>0.481203</td>\n",
       "      <td>0.033843</td>\n",
       "      <td>...</td>\n",
       "      <td>0.484864</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>-0.000053</td>\n",
       "      <td>0.100140</td>\n",
       "      <td>0.167965</td>\n",
       "      <td>0.000794</td>\n",
       "      <td>0.440430</td>\n",
       "      <td>-0.016335</td>\n",
       "      <td>0.473434</td>\n",
       "      <td>0.193096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.114583</td>\n",
       "      <td>0.421594</td>\n",
       "      <td>0.7875</td>\n",
       "      <td>0.174497</td>\n",
       "      <td>0.474860</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.636111</td>\n",
       "      <td>0.7775</td>\n",
       "      <td>0.739348</td>\n",
       "      <td>0.188891</td>\n",
       "      <td>...</td>\n",
       "      <td>0.720772</td>\n",
       "      <td>0.687302</td>\n",
       "      <td>-0.000511</td>\n",
       "      <td>0.079973</td>\n",
       "      <td>0.187557</td>\n",
       "      <td>0.001291</td>\n",
       "      <td>0.563832</td>\n",
       "      <td>-0.089779</td>\n",
       "      <td>0.700013</td>\n",
       "      <td>0.323749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>241</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.910026</td>\n",
       "      <td>0.7875</td>\n",
       "      <td>0.248322</td>\n",
       "      <td>0.474860</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.636111</td>\n",
       "      <td>0.7775</td>\n",
       "      <td>0.739348</td>\n",
       "      <td>0.188891</td>\n",
       "      <td>...</td>\n",
       "      <td>0.720772</td>\n",
       "      <td>0.687302</td>\n",
       "      <td>-0.000570</td>\n",
       "      <td>0.100331</td>\n",
       "      <td>0.499999</td>\n",
       "      <td>0.001526</td>\n",
       "      <td>0.715528</td>\n",
       "      <td>-0.181405</td>\n",
       "      <td>0.835001</td>\n",
       "      <td>0.522252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>242</td>\n",
       "      <td>0.258102</td>\n",
       "      <td>0.796915</td>\n",
       "      <td>0.5950</td>\n",
       "      <td>0.265101</td>\n",
       "      <td>0.163873</td>\n",
       "      <td>0.394444</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>0.5225</td>\n",
       "      <td>0.551378</td>\n",
       "      <td>0.191386</td>\n",
       "      <td>...</td>\n",
       "      <td>0.452505</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.001023</td>\n",
       "      <td>0.102013</td>\n",
       "      <td>0.001567</td>\n",
       "      <td>0.000550</td>\n",
       "      <td>0.604568</td>\n",
       "      <td>-0.738501</td>\n",
       "      <td>0.472639</td>\n",
       "      <td>0.393181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>243</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.676093</td>\n",
       "      <td>0.6900</td>\n",
       "      <td>0.489933</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.641667</td>\n",
       "      <td>0.641667</td>\n",
       "      <td>0.7375</td>\n",
       "      <td>0.739348</td>\n",
       "      <td>0.239213</td>\n",
       "      <td>...</td>\n",
       "      <td>0.687370</td>\n",
       "      <td>0.717460</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.167066</td>\n",
       "      <td>0.249264</td>\n",
       "      <td>0.001160</td>\n",
       "      <td>0.648457</td>\n",
       "      <td>-0.124471</td>\n",
       "      <td>0.615610</td>\n",
       "      <td>0.422904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>244 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Slope_minmax  PeakVal1_error  PeakVal2_error  PeakHt1_error  \\\n",
       "0        0.223958        0.786632          0.6925       0.379195   \n",
       "1        0.181818        0.370180          0.5000       0.197987   \n",
       "2        0.193182        0.519280          0.4700       0.308725   \n",
       "3        0.245536        0.383033          0.5350       0.305369   \n",
       "4        0.100216        0.336761          0.4000       0.171141   \n",
       "..            ...             ...             ...            ...   \n",
       "239      0.000000        0.431877          0.4100       0.147651   \n",
       "240      0.114583        0.421594          0.7875       0.174497   \n",
       "241      0.000000        0.910026          0.7875       0.248322   \n",
       "242      0.258102        0.796915          0.5950       0.265101   \n",
       "243      1.000000        0.676093          0.6900       0.489933   \n",
       "\n",
       "     PeakHt2_error  Min1_window  Min2_window  Max1_window  Max2_window  \\\n",
       "0         0.418994     0.672222     0.663889       0.7300     0.726817   \n",
       "1         0.242086     0.419444     0.391667       0.4900     0.466165   \n",
       "2         0.275605     0.250000     0.230556       0.3975     0.358396   \n",
       "3         0.175047     0.341667     0.327778       0.4225     0.403509   \n",
       "4         0.100559     0.311111     0.297222       0.3650     0.348371   \n",
       "..             ...          ...          ...          ...          ...   \n",
       "239       0.096834     0.483333     0.480556       0.5050     0.481203   \n",
       "240       0.474860     0.675000     0.636111       0.7775     0.739348   \n",
       "241       0.474860     0.675000     0.636111       0.7775     0.739348   \n",
       "242       0.163873     0.394444     0.425000       0.5225     0.551378   \n",
       "243       1.000000     0.641667     0.641667       0.7375     0.739348   \n",
       "\n",
       "     Var1_window  ...  Mean1_window  Mean2_window  Sig_coef1  Sig_coef2  \\\n",
       "0       0.151981  ...      0.702505      0.684127  -0.000191   0.156219   \n",
       "1       0.091495  ...      0.451461      0.428571  -0.000341   0.140436   \n",
       "2       0.190450  ...      0.328288      0.292593   0.000579   0.100817   \n",
       "3       0.098461  ...      0.382568      0.360847   0.000320   0.146757   \n",
       "4       0.049465  ...      0.338205      0.322222   0.000372   0.078657   \n",
       "..           ...  ...           ...           ...        ...        ...   \n",
       "239     0.033843  ...      0.484864      0.476190  -0.000053   0.100140   \n",
       "240     0.188891  ...      0.720772      0.687302  -0.000511   0.079973   \n",
       "241     0.188891  ...      0.720772      0.687302  -0.000570   0.100331   \n",
       "242     0.191386  ...      0.452505      0.500000   0.001023   0.102013   \n",
       "243     0.239213  ...      0.687370      0.717460  -0.000172   0.167066   \n",
       "\n",
       "     Sig_coef3  Sig_coef4   Max_fft   Min_fft  Mean_fft   Var_fft  \n",
       "0     0.005126   0.001271  0.704449 -0.305146  0.634014  0.501904  \n",
       "1     0.187519   0.000761  0.377450 -0.368154  0.351433  0.148848  \n",
       "2     0.003870   0.000368  0.376598 -0.543992  0.284399  0.155170  \n",
       "3     0.124742   0.000665  0.433015 -0.226763  0.418339  0.191966  \n",
       "4     0.002012   0.000429  0.374979 -0.273501  0.318875  0.145182  \n",
       "..         ...        ...       ...       ...       ...       ...  \n",
       "239   0.167965   0.000794  0.440430 -0.016335  0.473434  0.193096  \n",
       "240   0.187557   0.001291  0.563832 -0.089779  0.700013  0.323749  \n",
       "241   0.499999   0.001526  0.715528 -0.181405  0.835001  0.522252  \n",
       "242   0.001567   0.000550  0.604568 -0.738501  0.472639  0.393181  \n",
       "243   0.249264   0.001160  0.648457 -0.124471  0.615610  0.422904  \n",
       "\n",
       "[244 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Slope_minmax</th>\n",
       "      <th>PeakVal1_error</th>\n",
       "      <th>PeakVal2_error</th>\n",
       "      <th>PeakHt1_error</th>\n",
       "      <th>PeakHt2_error</th>\n",
       "      <th>Min1_window</th>\n",
       "      <th>Min2_window</th>\n",
       "      <th>Max1_window</th>\n",
       "      <th>Max2_window</th>\n",
       "      <th>Var1_window</th>\n",
       "      <th>...</th>\n",
       "      <th>Mean1_window</th>\n",
       "      <th>Mean2_window</th>\n",
       "      <th>Sig_coef1</th>\n",
       "      <th>Sig_coef2</th>\n",
       "      <th>Sig_coef3</th>\n",
       "      <th>Sig_coef4</th>\n",
       "      <th>Max_fft</th>\n",
       "      <th>Min_fft</th>\n",
       "      <th>Mean_fft</th>\n",
       "      <th>Var_fft</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.144231</td>\n",
       "      <td>0.501285</td>\n",
       "      <td>0.3575</td>\n",
       "      <td>0.154362</td>\n",
       "      <td>0.093110</td>\n",
       "      <td>0.447222</td>\n",
       "      <td>0.461111</td>\n",
       "      <td>0.4725</td>\n",
       "      <td>0.488722</td>\n",
       "      <td>0.034883</td>\n",
       "      <td>...</td>\n",
       "      <td>0.456159</td>\n",
       "      <td>0.480423</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.107789</td>\n",
       "      <td>0.001025</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.390830</td>\n",
       "      <td>-0.348937</td>\n",
       "      <td>0.337304</td>\n",
       "      <td>0.165106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.043750</td>\n",
       "      <td>0.228792</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.204698</td>\n",
       "      <td>0.232775</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.2625</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.013334</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251566</td>\n",
       "      <td>0.261905</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.056647</td>\n",
       "      <td>0.000748</td>\n",
       "      <td>0.000337</td>\n",
       "      <td>0.227373</td>\n",
       "      <td>-0.045013</td>\n",
       "      <td>0.223039</td>\n",
       "      <td>0.053624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.035511</td>\n",
       "      <td>0.221080</td>\n",
       "      <td>0.2350</td>\n",
       "      <td>0.144295</td>\n",
       "      <td>0.093110</td>\n",
       "      <td>0.205556</td>\n",
       "      <td>0.211111</td>\n",
       "      <td>0.2150</td>\n",
       "      <td>0.218045</td>\n",
       "      <td>0.006290</td>\n",
       "      <td>...</td>\n",
       "      <td>0.208246</td>\n",
       "      <td>0.217989</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.021406</td>\n",
       "      <td>0.000920</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>0.216550</td>\n",
       "      <td>-0.055635</td>\n",
       "      <td>0.207839</td>\n",
       "      <td>0.048761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.275064</td>\n",
       "      <td>0.2350</td>\n",
       "      <td>0.137584</td>\n",
       "      <td>0.229050</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.305556</td>\n",
       "      <td>0.3550</td>\n",
       "      <td>0.370927</td>\n",
       "      <td>0.072390</td>\n",
       "      <td>...</td>\n",
       "      <td>0.313152</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>-0.000037</td>\n",
       "      <td>0.245806</td>\n",
       "      <td>0.249993</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.277314</td>\n",
       "      <td>-0.029355</td>\n",
       "      <td>0.332700</td>\n",
       "      <td>0.079420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.380463</td>\n",
       "      <td>0.6275</td>\n",
       "      <td>0.164430</td>\n",
       "      <td>0.290503</td>\n",
       "      <td>0.558333</td>\n",
       "      <td>0.536111</td>\n",
       "      <td>0.6175</td>\n",
       "      <td>0.601504</td>\n",
       "      <td>0.098383</td>\n",
       "      <td>...</td>\n",
       "      <td>0.587161</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>-0.000291</td>\n",
       "      <td>0.974670</td>\n",
       "      <td>0.249876</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.442986</td>\n",
       "      <td>-0.055481</td>\n",
       "      <td>0.543379</td>\n",
       "      <td>0.204876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.149554</td>\n",
       "      <td>0.300771</td>\n",
       "      <td>0.5250</td>\n",
       "      <td>0.261745</td>\n",
       "      <td>0.171322</td>\n",
       "      <td>0.472222</td>\n",
       "      <td>0.455556</td>\n",
       "      <td>0.5250</td>\n",
       "      <td>0.506266</td>\n",
       "      <td>0.066724</td>\n",
       "      <td>...</td>\n",
       "      <td>0.498956</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.405744</td>\n",
       "      <td>-0.277090</td>\n",
       "      <td>0.358404</td>\n",
       "      <td>0.176746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>231</td>\n",
       "      <td>0.222656</td>\n",
       "      <td>0.562982</td>\n",
       "      <td>0.5600</td>\n",
       "      <td>0.419463</td>\n",
       "      <td>0.391061</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.552778</td>\n",
       "      <td>0.6175</td>\n",
       "      <td>0.598997</td>\n",
       "      <td>0.083775</td>\n",
       "      <td>...</td>\n",
       "      <td>0.588727</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>0.148974</td>\n",
       "      <td>0.014424</td>\n",
       "      <td>0.000983</td>\n",
       "      <td>0.565877</td>\n",
       "      <td>-0.091022</td>\n",
       "      <td>0.569134</td>\n",
       "      <td>0.331637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>232</td>\n",
       "      <td>0.142241</td>\n",
       "      <td>0.455013</td>\n",
       "      <td>0.5125</td>\n",
       "      <td>0.362416</td>\n",
       "      <td>0.420857</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.5475</td>\n",
       "      <td>0.538847</td>\n",
       "      <td>0.145482</td>\n",
       "      <td>...</td>\n",
       "      <td>0.512004</td>\n",
       "      <td>0.495238</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.522328</td>\n",
       "      <td>-0.240149</td>\n",
       "      <td>0.479270</td>\n",
       "      <td>0.287802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>233</td>\n",
       "      <td>0.200521</td>\n",
       "      <td>0.544987</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.224832</td>\n",
       "      <td>0.202980</td>\n",
       "      <td>0.397222</td>\n",
       "      <td>0.372222</td>\n",
       "      <td>0.4725</td>\n",
       "      <td>0.446115</td>\n",
       "      <td>0.084555</td>\n",
       "      <td>...</td>\n",
       "      <td>0.434760</td>\n",
       "      <td>0.411640</td>\n",
       "      <td>0.010670</td>\n",
       "      <td>-0.171320</td>\n",
       "      <td>0.000601</td>\n",
       "      <td>-0.009475</td>\n",
       "      <td>0.525652</td>\n",
       "      <td>-0.323542</td>\n",
       "      <td>0.417438</td>\n",
       "      <td>0.295973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>234</td>\n",
       "      <td>0.130208</td>\n",
       "      <td>0.622108</td>\n",
       "      <td>0.7300</td>\n",
       "      <td>0.328859</td>\n",
       "      <td>0.182495</td>\n",
       "      <td>0.627778</td>\n",
       "      <td>0.619444</td>\n",
       "      <td>0.6450</td>\n",
       "      <td>0.636591</td>\n",
       "      <td>0.049075</td>\n",
       "      <td>...</td>\n",
       "      <td>0.632568</td>\n",
       "      <td>0.622751</td>\n",
       "      <td>0.000261</td>\n",
       "      <td>0.051614</td>\n",
       "      <td>0.003595</td>\n",
       "      <td>0.001035</td>\n",
       "      <td>0.679905</td>\n",
       "      <td>-0.184297</td>\n",
       "      <td>0.631070</td>\n",
       "      <td>0.481748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>235 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Slope_minmax  PeakVal1_error  PeakVal2_error  PeakHt1_error  \\\n",
       "0        0.144231        0.501285          0.3575       0.154362   \n",
       "1        0.043750        0.228792          0.2575       0.204698   \n",
       "2        0.035511        0.221080          0.2350       0.144295   \n",
       "3        0.062500        0.275064          0.2350       0.137584   \n",
       "4        0.187500        0.380463          0.6275       0.164430   \n",
       "..            ...             ...             ...            ...   \n",
       "230      0.149554        0.300771          0.5250       0.261745   \n",
       "231      0.222656        0.562982          0.5600       0.419463   \n",
       "232      0.142241        0.455013          0.5125       0.362416   \n",
       "233      0.200521        0.544987          0.5625       0.224832   \n",
       "234      0.130208        0.622108          0.7300       0.328859   \n",
       "\n",
       "     PeakHt2_error  Min1_window  Min2_window  Max1_window  Max2_window  \\\n",
       "0         0.093110     0.447222     0.461111       0.4725     0.488722   \n",
       "1         0.232775     0.250000     0.250000       0.2625     0.263158   \n",
       "2         0.093110     0.205556     0.211111       0.2150     0.218045   \n",
       "3         0.229050     0.277778     0.305556       0.3550     0.370927   \n",
       "4         0.290503     0.558333     0.536111       0.6175     0.601504   \n",
       "..             ...          ...          ...          ...          ...   \n",
       "230       0.171322     0.472222     0.455556       0.5250     0.506266   \n",
       "231       0.391061     0.566667     0.552778       0.6175     0.598997   \n",
       "232       0.420857     0.466667     0.466667       0.5475     0.538847   \n",
       "233       0.202980     0.397222     0.372222       0.4725     0.446115   \n",
       "234       0.182495     0.627778     0.619444       0.6450     0.636591   \n",
       "\n",
       "     Var1_window  ...  Mean1_window  Mean2_window  Sig_coef1  Sig_coef2  \\\n",
       "0       0.034883  ...      0.456159      0.480423   0.000667   0.107789   \n",
       "1       0.013334  ...      0.251566      0.261905   0.000112   0.056647   \n",
       "2       0.006290  ...      0.208246      0.217989   0.000174   0.021406   \n",
       "3       0.072390  ...      0.313152      0.342857  -0.000037   0.245806   \n",
       "4       0.098383  ...      0.587161      0.566667  -0.000291   0.974670   \n",
       "..           ...  ...           ...           ...        ...        ...   \n",
       "230     0.066724  ...      0.498956      0.481481   0.000000   0.000000   \n",
       "231     0.083775  ...      0.588727      0.571429   0.000151   0.148974   \n",
       "232     0.145482  ...      0.512004      0.495238   0.000000   0.000000   \n",
       "233     0.084555  ...      0.434760      0.411640   0.010670  -0.171320   \n",
       "234     0.049075  ...      0.632568      0.622751   0.000261   0.051614   \n",
       "\n",
       "     Sig_coef3  Sig_coef4   Max_fft   Min_fft  Mean_fft   Var_fft  \n",
       "0     0.001025   0.000401  0.390830 -0.348937  0.337304  0.165106  \n",
       "1     0.000748   0.000337  0.227373 -0.045013  0.223039  0.053624  \n",
       "2     0.000920   0.000253  0.216550 -0.055635  0.207839  0.048761  \n",
       "3     0.249993   0.000499  0.277314 -0.029355  0.332700  0.079420  \n",
       "4     0.249876   0.000798  0.442986 -0.055481  0.543379  0.204876  \n",
       "..         ...        ...       ...       ...       ...       ...  \n",
       "230   0.000000   0.000000  0.405744 -0.277090  0.358404  0.176746  \n",
       "231   0.014424   0.000983  0.565877 -0.091022  0.569134  0.331637  \n",
       "232   0.000000   0.000000  0.522328 -0.240149  0.479270  0.287802  \n",
       "233   0.000601  -0.009475  0.525652 -0.323542  0.417438  0.295973  \n",
       "234   0.003595   0.001035  0.679905 -0.184297  0.631070  0.481748  \n",
       "\n",
       "[235 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cgmData = pd.read_csv(\"ComparisonData/mealData\" + str(1) + '.csv', names=list(range(50)))\n",
    "for i in file_no[1:]:\n",
    "    cgm = pd.read_csv(\"ComparisonData/mealData\" + str(i) + '.csv', names=list(range(50)))\n",
    "    cgmData = cgmData.append(cgm)\n",
    "cgmData = cgmData.dropna(axis='columns', how='all')\n",
    "cgmData = cgmData.mask(cgmData.eq(-1)).ffill(axis=1)\n",
    "\n",
    "zero_entries = cgmData.isna().any(axis=1)\n",
    "cgmData = cgmData[zero_entries == False]\n",
    "\n",
    "cgmValues_np = cgmData.values\n",
    "cgmNorm_np = cgmValues_np/400.0\n",
    "\n",
    "length = len(cgmNorm_np[0])\n",
    "cgmSeries_np = [0.0833*(length-i-1) for i in range(0, length)]\n",
    "cgmSeries_np = np.array(cgmSeries_np)\n",
    "features = MergedFeatures(cgmNorm_np, cgmSeries_np)\n",
    "features_df = GenerateDF(features, COLUMNS)\n",
    "max_scale = features_df.abs().max(axis=0)\n",
    "max_scale.to_pickle('DataScale.pkl')\n",
    "normal_df = NormalizeDF(features_df, COLUMNS, max_scale)\n",
    "display(normal_df)\n",
    "normal_df.to_csv('MealFeatures.csv', index=False)\n",
    "\n",
    "cgmData = pd.read_csv(\"ComparisonData/Nomeal\" + str(1) + '.csv', names=list(range(50)))\n",
    "for i in file_no[1:]:\n",
    "    cgm = pd.read_csv(\"ComparisonData/Nomeal\" + str(i) + '.csv', names=list(range(50)))\n",
    "    cgmData = cgmData.append(cgm)\n",
    "cgmData = cgmData.dropna(axis='columns', how='all')\n",
    "cgmData = cgmData.mask(cgmData.eq(-1)).ffill(axis=1)\n",
    "\n",
    "zero_entries = cgmData.isna().any(axis=1)\n",
    "cgmData = cgmData[zero_entries == False]\n",
    "\n",
    "cgmValues_np = cgmData.values\n",
    "cgmNorm_np = cgmValues_np/400.0\n",
    "\n",
    "length = len(cgmNorm_np[0])\n",
    "cgmSeries_np = [0.0833*(length-i-1) for i in range(0, length)]\n",
    "cgmSeries_np = np.array(cgmSeries_np)\n",
    "features = MergedFeatures(cgmNorm_np, cgmSeries_np)\n",
    "features_df = GenerateDF(features, COLUMNS)\n",
    "normal_df = NormalizeDF(features_df, COLUMNS, max_scale)\n",
    "display(normal_df)\n",
    "normal_df.to_csv('NoMealFeatures.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Generating PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCA_filename = 'PCA.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GeneratePCA(data, PCA_filename):\n",
    "    pca = PCA(n_components=5)\n",
    "    pca.fit(data)\n",
    "    components = pca.components_\n",
    "    variances = pca.explained_variance_\n",
    "    x = [i for i in range(0, len(components[0]))]\n",
    "    for i in range(0, 5):\n",
    "        plt.figure()\n",
    "        plt.bar(x, components[i])\n",
    "        plt.xticks(np.arange(len(components[0])), x, rotation=90)\n",
    "        plt.show()\n",
    "        positives = np.array(np.argwhere(components[i] > 0).flatten())\n",
    "        positive_sorted = np.argsort(components[i][:])\n",
    "    PCA_file = open(PCA_filename, 'wb')\n",
    "    pickle.dump(pca, PCA_file)\n",
    "    PCA_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Transform(data, PCA_filename):\n",
    "    PCA_file = open(PCA_filename, 'rb')\n",
    "    pca = pickle.load(PCA_file)\n",
    "    PCA_file.close()\n",
    "    return pca.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD7CAYAAABpJS8eAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAATT0lEQVR4nO3de7CcdX3H8feXxDDScAkQIALhMIqleAM5E9GqoIANpRDaYgVbCY4007EUR21LOjjaYmsDjLeO0JqKCnhBwAupBLkJ9CbI4SKCERMwQMotXMRBsIh++8fzxK7rXs6eZ885yfm9XzPPnGef5/fb7+/s2fPZZ3+7+2xkJpKkmW+r6R6AJGlqGPiSVAgDX5IKYeBLUiEMfEkqhIEvSYWYPd0D6GbnnXfOkZGR6R6GJG1Rbr755kczc36nfZtt4I+MjDA2Njbdw5CkLUpE3Ntt31CmdCJicUTcFRHrImJ5j3bHRkRGxOgw6kqSxq9x4EfELOBs4AhgP+D4iNivQ7ttgVOAG5vWlCQNbhhH+IuAdZl5T2Y+C1wILOnQ7oPAmcBPh1BTkjSgYQT+7sD9LZc31Nt+KSIOAPbMzK8PoZ4kaQKGEfjRYdsvz8gWEVsBHwXe2/eKIpZFxFhEjG3cuHEIQ5MkbTKMwN8A7NlyeQ/ggZbL2wIvBa6LiPXAQcCqTi/cZubKzBzNzNH58zu+q0iSNEHDCPybgH0iYu+ImAMcB6zatDMzn8zMnTNzJDNHgBuAozPT91xK0hRq/D78zHwuIk4GrgBmAZ/OzDsj4nRgLDNX9b4GAYwsv2zcbdevOHISRyJpphrKB68yczWwum3b+7u0PWQYNSVJg/FcOpJUCANfkgph4EtSIQx8SSqEgS9JhTDwJakQBr4kFcLAl6RCGPiSVAgDX5IKYeBLUiEMfEkqxFBOniZtzgY5Eyl4NlLNXB7hS1IhDHxJKoRTOlIPTgdpJpmxge83SEnSr3JKR5IKYeBLUiEMfEkqhIEvSYUw8CWpEAa+JBXCwJekQhj4klQIA1+SCjFjP2lbCj/6L2m8PMKXpEIY+JJUCANfkgph4EtSIQx8SSqEgS9JhRhK4EfE4oi4KyLWRcTyDvvfExHfi4jbI+KaiNhrGHUlSePXOPAjYhZwNnAEsB9wfETs19bsVmA0M18OXAKc2bSuJGkwwzjCXwSsy8x7MvNZ4EJgSWuDzLw2M5+uL94A7DGEupKkAQwj8HcH7m+5vKHe1s07gMs77YiIZRExFhFjGzduHMLQJEmbDCPwo8O27Ngw4k+AUeCsTvszc2Vmjmbm6Pz584cwNEnSJsM4l84GYM+Wy3sAD7Q3iojDgNOAgzPzf4dQV5I0gGEc4d8E7BMRe0fEHOA4YFVrg4g4APgkcHRmPjKEmpKkATUO/Mx8DjgZuAJYA1yUmXdGxOkRcXTd7CxgLnBxRNwWEau6XJ0kaZIM5fTImbkaWN227f0t64cNo44kaeL8pK0kFcLAl6RCGPiSVAgDX5IKYeBLUiEMfEkqhIEvSYUw8CWpEAa+JBXCwJekQhj4klSIoZxLZyYZWX7ZQO3XrzhykkYiScPlEb4kFcLAl6RCGPiSVAgDX5IKYeBLUiEMfEkqhIEvSYUw8CWpEAa+JBXCT9pK0iTbXD7B7xG+JBXCwJekQjilI2mLs7lMkWxpPMKXpEIY+JJUCANfkgrhHP4QOa8oaXPmEb4kFcIjfE0pnwVJ08fA1xZjkAcLHyikX2fgSzOIz6DUy1Dm8CNicUTcFRHrImJ5h/1bR8SX6v03RsTIMOpKksavceBHxCzgbOAIYD/g+IjYr63ZO4AnMvNFwEeBM5rWlSQNZhhH+IuAdZl5T2Y+C1wILGlrswQ4r16/BDg0ImIItSVJ4xSZ2ewKIo4FFmfmSfXltwGvysyTW9rcUbfZUF++u27zaNt1LQOWASxcuPDAe++9t9HY1NtE53udJx6fib7IPF2373SMdzp+16ka73Td7yPi5swc7bRvGEf4nY7U2x9FxtOGzFyZmaOZOTp//vwhDE2StMkwAn8DsGfL5T2AB7q1iYjZwPbA40OoLUkap2EE/k3APhGxd0TMAY4DVrW1WQUsrdePBb6ZTeeSJEkDafw+/Mx8LiJOBq4AZgGfzsw7I+J0YCwzVwHnAhdExDqqI/vjmtaVtOUr9fWd6TKUD15l5mpgddu297es/xR48zBqSZochu/M58nTJKkQBr4kFcLAl6RCePI0aZI4J67NjYEvbWZ8oNBkcUpHkgph4EtSIQx8SSqEgS9JhTDwJakQBr4kFcLAl6RCGPiSVAgDX5IKYeBLUiEMfEkqhIEvSYUw8CWpEAa+JBXCwJekQng+fEkapy39uwoM/IJN9M67pd/ppVI5pSNJhTDwJakQBr4kFcLAl6RCGPiSVAgDX5IKYeBLUiEMfEkqhIEvSYUw8CWpEI0CPyJ2jIirImJt/XNehzb7R8S3IuLOiLg9It7SpKYkaWKaHuEvB67JzH2Aa+rL7Z4GTsjMlwCLgY9FxA4N60qSBtQ08JcA59Xr5wHHtDfIzB9k5tp6/QHgEWB+w7qSpAE1DfxdM/NBgPrnLr0aR8QiYA5wd8O6kqQB9T09ckRcDezWYddpgxSKiAXABcDSzPxFlzbLgGUACxcuHOTqJUl99A38zDys276IeDgiFmTmg3WgP9Kl3XbAZcD7MvOGHrVWAisBRkdHs9/YJEnj13RKZxWwtF5fClza3iAi5gBfBc7PzIsb1pMkTVDTwF8BHB4Ra4HD68tExGhEfKpu80fA64ETI+K2etm/YV1J0oAafcVhZj4GHNph+xhwUr3+OeBzTepIkprzk7aSVAgDX5IKYeBLUiEMfEkqhIEvSYUw8CWpEAa+JBXCwJekQhj4klQIA1+SCmHgS1IhDHxJKoSBL0mFMPAlqRAGviQVwsCXpEIY+JJUCANfkgph4EtSIQx8SSqEgS9JhZg93QOQtGVbv+LI6R6CxskjfEkqhIEvSYUw8CWpEAa+JBXCwJekQhj4klQIA1+SCmHgS1IhDHxJKoSBL0mFMPAlqRCNAj8idoyIqyJibf1zXo+220XE/0TEJ5rUlCRNTNMj/OXANZm5D3BNfbmbDwLXN6wnSZqgpoG/BDivXj8POKZTo4g4ENgVuLJhPUnSBDUN/F0z80GA+ucu7Q0iYivgw8Bf9buyiFgWEWMRMbZx48aGQ5Mktep7PvyIuBrYrcOu08ZZ453A6sy8PyJ6NszMlcBKgNHR0Rzn9UuSxqFv4GfmYd32RcTDEbEgMx+MiAXAIx2avRp4XUS8E5gLzImIpzKz13y/JGnImn7j1SpgKbCi/nlpe4PM/ONN6xFxIjBq2EvS1Gs6h78CODwi1gKH15eJiNGI+FTTwUmShqfREX5mPgYc2mH7GHBSh+2fBT7bpKYkaWL8pK0kFcLAl6RCGPiSVAgDX5IKYeBLUiEMfEkqhIEvSYUw8CWpEAa+JBXCwJekQhj4klQIA1+SCmHgS1IhDHxJKoSBL0mFMPAlqRAGviQVwsCXpEIY+JJUCANfkgph4EtSIQx8SSqEgS9JhTDwJakQBr4kFcLAl6RCGPiSVAgDX5IKYeBLUiFmT/cAJGkqrV9x5HQPYdp4hC9JhTDwJakQjQI/InaMiKsiYm39c16Xdgsj4sqIWBMR34uIkSZ1JUmDa3qEvxy4JjP3Aa6pL3dyPnBWZv4WsAh4pGFdSdKAmgb+EuC8ev084Jj2BhGxHzA7M68CyMynMvPphnUlSQNqGvi7ZuaDAPXPXTq0eTHwo4j4SkTcGhFnRcSshnUlSQPq+7bMiLga2K3DrtMGqPE64ADgPuBLwInAuR1qLQOWASxcuHCcVy9JGo++gZ+Zh3XbFxEPR8SCzHwwIhbQeW5+A3BrZt5T9/kacBAdAj8zVwIrAUZHR3N8v4IkaTyaTumsApbW60uBSzu0uQmYFxHz68tvBL7XsK4kaUCROfED6YjYCbgIWEg1XfPmzHw8IkaBP8vMk+p2hwMfBgK4GViWmc/2ue6NwL0THlx3OwOPTmG/La1mk76Od/Os2aSv453cvk1qdrNXZs7vuCczi1qAsanst6XVdLwzr6bj3Xz7Nqk5kcVP2kpSIQx8SSpEiYG/cor7bWk1m/R1vJtnzSZ9He/k9m1Sc2CNXrSVJG05SjzCl6QiGfiSVAgDX5IKMaO/4jAi9qU6o+fuQAIPAKsyc80U1N0duDEzn2rZvjgzv9Gj3yIgM/Om+iyji4HvZ+bqAeufn5knTGDcr6U6ffUdmXlln7avAtZk5o8j4vlUp8Z+JdWnqD+UmU/26HsK8NXMvH/A8c0BjgMeyMyrI+KtwGuANcDKzPxZn/4vBH4f2BN4DlgLfLHXWKWZZMa+aBsRpwLHAxdSnc8HYA+qwLgwM1dM8Hrfnpmf6bH/FODPqUJof+BdmXlpve+WzHxll34fAI6gehC+CngVcB1wGHBFZv5Dl36r2jcBbwC+CZCZR/cY67czc1G9/qf1uL8KvAn4t163UUTcCbwiM5+LiJXA08AlwKH19j/o0fdJ4CfA3cAXgYszc2O39i39Pk91+2wD/AiYC3ylrhmZubRH31OAo4Drgd8FbgOeoHoAeGdmXtevfqkiYpfMnNLvsIiInTLzsamsOdkiYnvgb6hOI7/pk7CPUJ2SZkVm/mjSBzGVn/KaygX4AfC8DtvnAGsbXO99ffZ/F5hbr48AY1ShD9VJ5Hr1m0UVZj8Gtqu3Px+4vUe/W4DPAYcAB9c/H6zXD+4z1ltb1m8C5tfrvwF8t0/fNa1jaNt3W7+6VNOJb6I6id5G4BtU52Patke/2+ufs4GHgVn15eh1G7XevvX6NsB19frCXn+Xus32wArg+8Bj9bKm3rZDg/vS5T32bQf8I3AB8Na2fef0ud7dgH8GzgZ2Av62/v0vAhb06btj27ITsB6YB+zYo9/ittvrXOB24AtUp1HvVXMFsHO9PgrcA6yjOrVK1/twfd9/H/DCCdz2o8C19f/OnlQHWU/W/wcH9Ok7FzgduLPusxG4ATixT78rgFOB3dr+VqcCV030fjTIMpPn8H8BvKDD9gX1vq4i4vYuy3eBXfvUnZX1NE5mrqcK4CMi4iNUwdTNc5n586y+HObuzPxxfR3P9BnvKNX5iU4DnszqSPWZzLw+M6/vM9atImJefU6kyPooOzN/QjXl0csdEfH2ev079fmTiIgXAz2nVqoS+YvMvDIz30H1dzqHagrrnj7jnQNsSxXa29fbtwae16cm/P8U5tb1dZCZ942j70VUzwYOycydMnMnqmdRTwAX9+oYEa/sshxI9Qywm89Q3V++DBwXEV+OiK3rfQf1Ge9nqabW7qcKtWeAI4H/AP6lT99Hqe5Pm5YxqunJW+r1bj7Usv5hqoOOo6gC9JN9ah6ZmZvOJ3MW8JbMfBGw6Rxc3cwDdgCujYhvR8S7I6LT/3wn5wBnApcB/w18MjO3p5qaPKdP389T3U9/B/g74J+AtwFviIgP9eg3kplnZOZDmzZk5kOZeQbVgcfkm4pHlelYqMJjHXA51YcbVlIdRa6j5WikS9+Hqf4Z92pbRqjmj3v1/Sawf9u22VRf8/jzHv1uBLap17dq2b49bUfQXfrvQRU+n6DPs5CWPuup7rg/rH/uVm+fS/+j9O2pguXueuw/q6/jeqopnV59ez3TeX6Pfe+ua9wLnEL1tZr/SnX0+oE+Nd9FdcS5kupI/e319vnAv/fpe9dE9tX7f17fJ67tsDzTo99tbZdPA/6L6oi75/2BX33mdl+v6+3Q9y/r/5OXtWz74TjuS7d0qzGOmt+n+lY8gBva9nV9ptlW83VUQf1Qfdsua3Ab9XvG9522yzfVP7eies2tW78rgb+m5RkP1QHkqcDV/W7jYSyTXmA6l/oPcBDwh8Cx9fqscfQ7F3htl31f6NN3D1qesrXt++0e/bbusn3n1n++cYz9SKoXTZvcbtsAe4+z7bbAK4AD6fPUvaXPixuM7QXAC+r1Heq/66Jx9n1J3X7fAWtO+B8VuAPYp8u++3v0W0PLA3+9bSnVNMK9fWp+p2X979v29Zyqq9tsOnj4SP33vWccfTYA7wHeS/WgHC37+k23/UV9G7+RavrpY8DrqY6eL+jR79ce+KimRRcDn+lT81tUU4pvpjqAOKbefjB9TmhG9YzgtfX6UVSvsW3a1+vgYB5wBtUD3BPA4/Xf+Qx6TJcNc5n0Ai4uW/rS9o/6eNs/6rw+fY8FfrPLvmN69DsTOKzD9sX0eQ2Kan55boftLwIuGeD3PopqbvqhcbT9QNuy6fWg3YDzx9H/EKpvw7uV6hnbaqpvv5vdo8+FDf6mr6CaU78c2Bf4ONUbAe4EXtOn78uBb9ft/5P6AIbq2eIpffruS/VGjLlt23vOOgztvjwVRVxcZupCPTU0lX2nsibVmwZeuqWMdzpr9utLNQ15F/A1qunUJS37+k7bDmOZsW/LlKZCRNyXmRN6wW2ifaejZpO+pdTs17d+08erM/OpiBihehvzBZn58Yi4NTMPmEjNQczoD15JwxARt3fbRZ93bU2073TUbNK3lJoN+/7KO/gi4hDgkojYi97v4BsaA1/qb1eqt+A90bY9qF7Am4y+01GzSd9Sajbp+1BE7J+ZtwHUR/q/B3waeFmfmkNh4Ev9fZ3qRbbb2ndExHWT1Hc6ajbpW0rNJn1PoO3zLZn5HHBCRPT7rMJQOIcvSYWYyZ+0lSS1MPAlqRAGviQVwsCXpEIY+JJUiP8DIwEl+ll+g14AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mealData = pd.read_csv('MealFeatures.csv')\n",
    "noMealData = pd.read_csv('NoMealFeatures.csv')\n",
    "\n",
    "GeneratePCA(mealData, PCA_filename)\n",
    "mealTransform = Transform(mealData, PCA_filename)\n",
    "noMealTransform = Transform(noMealData, PCA_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mealLabels = np.ones((mealTransform.shape[0], 1))\n",
    "noMealLabels = np.zeros((noMealTransform.shape[0], 1))\n",
    "\n",
    "mealDataWithLabels = np.concatenate((mealTransform, mealLabels), axis=1)\n",
    "noMealDataWithLabels = np.concatenate((noMealTransform, noMealLabels), axis=1)\n",
    "\n",
    "dataset = np.concatenate((mealDataWithLabels, noMealDataWithLabels), axis=0)\n",
    "np.random.shuffle(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifiers:\n",
    "    def __init__(self):\n",
    "        return\n",
    "    \n",
    "    def genClassifier1(self):\n",
    "        self.Classifier1 = SVC(kernel='rbf', gamma='auto')\n",
    "#         self.Classifier1 = NuSVC(nu=0.9, kernel='rbf', gamma='auto')\n",
    "        \n",
    "    def trainClassifier1(self, train_data):\n",
    "        self.genClassifier1()\n",
    "        self.Classifier1.fit(train_data[:, :-1], train_data[:, -1])\n",
    "        \n",
    "    def validateClassifier1(self, test_data):\n",
    "        labels = self.Classifier1.predict(test_data[:, :-1])\n",
    "        return labels\n",
    "    \n",
    "    def loadClassifier1(self, filename):\n",
    "        return\n",
    "        \n",
    "    def saveClassifier1(self, filename):\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(test_labels, labels):\n",
    "    TP = 0.0\n",
    "    FP = 0.0\n",
    "    TN = 0.0\n",
    "    FN = 0.0\n",
    "    base = len(labels)\n",
    "    for i in range(len(labels)):\n",
    "        if labels[i] == 1:\n",
    "            if test_labels[i] == 1:\n",
    "                TP += 1\n",
    "            else:\n",
    "                FP += 1\n",
    "        else:\n",
    "            if test_labels[i] == 0:\n",
    "                TN += 1\n",
    "            else:\n",
    "                FN += 1\n",
    "    acc = (TP+TN)/base\n",
    "    prec = (TP)/(TP+FP)\n",
    "    rec = (TP)/(TP+FN)\n",
    "    return acc, prec, rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc = 0.750000, Prec = 0.707692, Rec = 0.901961, F1 = 0.793103\n",
      "Acc = 0.687500, Prec = 0.650000, Rec = 0.812500, F1 = 0.722222\n",
      "Acc = 0.625000, Prec = 0.606557, Rec = 0.755102, F1 = 0.672727\n",
      "Acc = 0.666667, Prec = 0.650000, Rec = 0.780000, F1 = 0.709091\n",
      "Acc = 0.789474, Prec = 0.732143, Rec = 0.891304, F1 = 0.803922\n",
      "MEAN: Acc = 0.703728, Prec = 0.669279, Rec = 0.828173, F1 = 0.740296\n"
     ]
    }
   ],
   "source": [
    "no_k = 5\n",
    "kf = KFold(no_k)\n",
    "total_acc = 0.0\n",
    "total_prec = 0.0\n",
    "total_rec = 0.0\n",
    "models = Classifiers()\n",
    "for train, test in kf.split(dataset):\n",
    "    models.trainClassifier1(dataset[train])\n",
    "    labels = models.validateClassifier1(dataset[test])\n",
    "    acc, prec, rec = evaluate(dataset[test][:, -1], labels)\n",
    "    total_acc += acc\n",
    "    total_prec += prec\n",
    "    total_rec += rec\n",
    "    print(\"Acc = %f, Prec = %f, Rec = %f, F1 = %f\" %(acc, prec, rec, 2*prec*rec/(prec+rec)))\n",
    "print(\"MEAN: Acc = %f, Prec = %f, Rec = %f, F1 = %f\" %(total_acc/no_k, total_prec/no_k, total_rec/no_k, 2*total_prec*total_rec/(no_k*(total_prec+total_rec))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Classifier (Neural network- Multi-layer Perceptron AND Gaussian Process Classifier) -Vedant Salvi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc = 0.812500, Prec = 0.863636, Rec = 0.760000, F1 = 0.808511\n",
      "Acc = 0.729167, Prec = 0.709677, Rec = 0.846154, F1 = 0.771930\n",
      "Acc = 0.854167, Prec = 0.827586, Rec = 0.923077, F1 = 0.872727\n",
      "Acc = 0.750000, Prec = 0.666667, Rec = 0.909091, F1 = 0.769231\n",
      "Acc = 0.750000, Prec = 0.676471, Rec = 0.958333, F1 = 0.793103\n",
      "Acc = 0.708333, Prec = 0.720000, Rec = 0.720000, F1 = 0.720000\n",
      "Acc = 0.687500, Prec = 0.724138, Rec = 0.750000, F1 = 0.736842\n",
      "Acc = 0.895833, Prec = 0.869565, Rec = 0.909091, F1 = 0.888889\n",
      "Acc = 0.812500, Prec = 0.769231, Rec = 0.869565, F1 = 0.816327\n",
      "Acc = 0.893617, Prec = 0.846154, Rec = 0.956522, F1 = 0.897959\n",
      "MEAN: Acc = 0.789362, Prec = 0.767313, Rec = 0.860183, F1 = 0.811098\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "no_k = 10\n",
    "kf = KFold(no_k)\n",
    "total_acc = 0.0\n",
    "total_prec = 0.0\n",
    "total_rec = 0.0\n",
    "gpc = None\n",
    "test_data=None\n",
    "#models = Classifiers()\n",
    "for train, test in kf.split(dataset):\n",
    "    kernel = 1.0 * RBF(1.0)\n",
    "    gpc = GaussianProcessClassifier(kernel=kernel,random_state=0)\n",
    "    mlp = MLPClassifier(solver='lbfgs',activation ='tanh', alpha=1e-5,hidden_layer_sizes=(4,4), random_state=1)\n",
    "    ensembleClassifier = VotingClassifier(estimators=[('gpc', gpc), ('mlp', mlp)],voting='soft')\n",
    "    ensembleClassifier = ensembleClassifier.fit(dataset[train][:, :-1], dataset[train][:, -1])\n",
    "    #gpc.score(dataset[train][:, :-1], dataset[train][:, -1])\n",
    "    labels = ensembleClassifier.predict(dataset[test][:, :-1])\n",
    "    acc, prec, rec = evaluate(dataset[test][:, -1], labels)\n",
    "    total_acc += acc\n",
    "    total_prec += prec\n",
    "    total_rec += rec\n",
    "    test_data=dataset[test]\n",
    "    print(\"Acc = %f, Prec = %f, Rec = %f, F1 = %f\" %(acc, prec, rec, 2*prec*rec/(prec+rec)))\n",
    "print(\"MEAN: Acc = %f, Prec = %f, Rec = %f, F1 = %f\" %(total_acc/no_k, total_prec/no_k, total_rec/no_k, 2*total_prec*total_rec/(no_k*(total_prec+total_rec))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc = 0.893617, Prec = 0.846154, Rec = 0.956522, F1 = 0.897959\n",
      "MEAN: Acc = 0.878723, Prec = 0.851928, Rec = 0.955835, F1 = 0.900895\n"
     ]
    }
   ],
   "source": [
    "joblib.dump(ensembleClassifier, 'gpc.pkl') \n",
    "gpc_from_joblib = joblib.load('gpc.pkl')  \n",
    "labels = gpc_from_joblib.predict(dataset[test][:, :-1]) \n",
    "acc, prec, rec = evaluate(dataset[test][:, -1], labels)\n",
    "total_acc += acc\n",
    "total_prec += prec\n",
    "total_rec += rec\n",
    "test_data=dataset[test]\n",
    "print(\"Acc = %f, Prec = %f, Rec = %f, F1 = %f\" %(acc, prec, rec, 2*prec*rec/(prec+rec)))\n",
    "print(\"MEAN: Acc = %f, Prec = %f, Rec = %f, F1 = %f\" %(total_acc/no_k, total_prec/no_k, total_rec/no_k, 2*total_prec*total_rec/(no_k*(total_prec+total_rec))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voting Classifier (Omkar Muglikar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc = 0.822917, Prec = 0.774194, Rec = 0.941176, F1 = 0.849558\n",
      "Acc = 0.739583, Prec = 0.701754, Rec = 0.833333, F1 = 0.761905\n",
      "Acc = 0.760417, Prec = 0.724138, Rec = 0.857143, F1 = 0.785047\n",
      "Acc = 0.791667, Prec = 0.750000, Rec = 0.900000, F1 = 0.818182\n",
      "Acc = 0.789474, Prec = 0.750000, Rec = 0.847826, F1 = 0.795918\n",
      "MEAN: Acc = 0.780811, Prec = 0.740017, Rec = 0.875896, F1 = 0.802244\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomTreesEmbedding,VotingClassifier\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "no_k = 5\n",
    "kf = KFold(no_k)\n",
    "total_acc = 0.0\n",
    "total_prec = 0.0\n",
    "total_rec = 0.0\n",
    "gpc = None\n",
    "test_data=None\n",
    "#models = Classifiers()\n",
    "for train, test in kf.split(dataset):\n",
    "    rf1 = RandomForestClassifier(n_estimators=50, max_depth=6,random_state=0)#.fit(dataset[train][:, :-1], dataset[train][:, -1])\n",
    "    rf2 = AdaBoostClassifier(n_estimators=50, random_state=0)#.fit(dataset[train][:, :-1], dataset[train][:, -1])\n",
    "    kernel = 1.0 * RBF(1.0)\n",
    "    rf3 = GaussianProcessClassifier(kernel=kernel,random_state=0)#.fit(dataset[train][:, :-1], dataset[train][:, -1])\n",
    "    rf4 = SVC(kernel='rbf', gamma='auto')#.fit(dataset[train][:, :-1], dataset[train][:, -1])\n",
    "    \n",
    "    \n",
    "    vclf = VotingClassifier(estimators=[('rf', rf1), ('ab', rf2), ('gpc', rf3), ('svm',rf4)], voting='hard', weights=[2,0.9,0.5,0.3])\n",
    "    vclf.fit(dataset[train][:, :-1], dataset[train][:, -1])\n",
    "    \n",
    "    \n",
    "    vclf.score(dataset[train][:, :-1], dataset[train][:, -1])\n",
    "    labels = vclf.predict(dataset[test][:, :-1])\n",
    "    \n",
    "    acc, prec, rec = evaluate(dataset[test][:, -1], labels)\n",
    "    total_acc += acc\n",
    "    total_prec += prec\n",
    "    total_rec += rec\n",
    "    test_data=dataset[test]\n",
    "    print(\"Acc = %f, Prec = %f, Rec = %f, F1 = %f\" %(acc, prec, rec, 2*prec*rec/(prec+rec)))\n",
    "print(\"MEAN: Acc = %f, Prec = %f, Rec = %f, F1 = %f\" %(total_acc/no_k, total_prec/no_k, total_rec/no_k, 2*total_prec*total_rec/(no_k*(total_prec+total_rec))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vclf.pkl']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(vclf, 'vclf.pkl') \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc = 0.927083, Prec = 0.879310, Rec = 1.000000, F1 = 0.935780\n",
      "Acc = 0.906250, Prec = 0.867925, Rec = 0.958333, F1 = 0.910891\n",
      "Acc = 0.854167, Prec = 0.786885, Rec = 0.979592, F1 = 0.872727\n",
      "Acc = 0.875000, Prec = 0.816667, Rec = 0.980000, F1 = 0.890909\n",
      "Acc = 0.789474, Prec = 0.750000, Rec = 0.847826, F1 = 0.795918\n",
      "MEAN: Acc = 0.870395, Prec = 0.820157, Rec = 0.953150, F1 = 0.881667\n"
     ]
    }
   ],
   "source": [
    "no_k = 5\n",
    "kf = KFold(no_k)\n",
    "total_acc = 0.0\n",
    "total_prec = 0.0\n",
    "total_rec = 0.0\n",
    "gpc = None\n",
    "test_data=None\n",
    "vclf_from_joblib = joblib.load('vclf.pkl')\n",
    "\n",
    "for train, test in kf.split(dataset):\n",
    "\n",
    "    labels = vclf_from_joblib.predict(dataset[test][:, :-1]) \n",
    "    acc, prec, rec = evaluate(dataset[test][:, -1], labels)\n",
    "    total_acc += acc\n",
    "    total_prec += prec\n",
    "    total_rec += rec\n",
    "    test_data=dataset[test]\n",
    "    print(\"Acc = %f, Prec = %f, Rec = %f, F1 = %f\" %(acc, prec, rec, 2*prec*rec/(prec+rec)))\n",
    "print(\"MEAN: Acc = %f, Prec = %f, Rec = %f, F1 = %f\" %(total_acc/no_k, total_prec/no_k, total_rec/no_k, 2*total_prec*total_rec/(no_k*(total_prec+total_rec))))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(384, 5)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[train][:, :-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[test][:, -1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Decision Tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc = 0.718750, Prec = 0.671429, Rec = 0.921569, F1 = 0.776860\n",
      "Acc = 0.697917, Prec = 0.650794, Rec = 0.854167, F1 = 0.738739\n",
      "Acc = 0.697917, Prec = 0.661290, Rec = 0.836735, F1 = 0.738739\n",
      "Acc = 0.750000, Prec = 0.691176, Rec = 0.940000, F1 = 0.796610\n",
      "Acc = 0.789474, Prec = 0.724138, Rec = 0.913043, F1 = 0.807692\n",
      "MEAN: Acc = 0.730811, Prec = 0.679765, Rec = 0.893103, F1 = 0.771966\n"
     ]
    }
   ],
   "source": [
    "no_k = 5\n",
    "kf = KFold(no_k)\n",
    "total_acc = 0.0\n",
    "total_prec = 0.0\n",
    "total_rec = 0.0\n",
    "models = Classifiers()\n",
    "for train, test in kf.split(dataset):\n",
    "    dt=DecisionTreeClassifier(max_depth=5)\n",
    "    gnb=GaussianNB()\n",
    "    ensembleClassifier = VotingClassifier(estimators=[('dt',dt), ('gnb',gnb)],voting='soft')\n",
    "    ensembleClassifier = ensembleClassifier.fit(dataset[train][:, :-1], dataset[train][:, -1])\n",
    "    labels = ensembleClassifier.predict(dataset[test][:, :-1])\n",
    "    acc, prec, rec = evaluate(dataset[test][:, -1], labels)\n",
    "    total_acc += acc\n",
    "    total_prec += prec\n",
    "    total_rec += rec\n",
    "    print(\"Acc = %f, Prec = %f, Rec = %f, F1 = %f\" %(acc, prec, rec, 2*prec*rec/(prec+rec)))\n",
    "print(\"MEAN: Acc = %f, Prec = %f, Rec = %f, F1 = %f\" %(total_acc/no_k, total_prec/no_k, total_rec/no_k, 2*total_prec*total_rec/(no_k*(total_prec+total_rec))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
